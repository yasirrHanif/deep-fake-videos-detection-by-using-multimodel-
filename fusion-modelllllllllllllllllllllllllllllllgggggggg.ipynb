{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9356447,"sourceType":"datasetVersion","datasetId":5672208},{"sourceId":13698842,"sourceType":"datasetVersion","datasetId":8713854},{"sourceId":14182262,"sourceType":"datasetVersion","datasetId":9041407},{"sourceId":674611,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":511361,"modelId":526039},{"sourceId":674614,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":511363,"modelId":526040},{"sourceId":674638,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":511380,"modelId":526056}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\n'''# =======================================\n# 0) Imports\nimport tempfile\nimport subprocess\n# =======================================\nimport os\nimport torch\nimport pickle\nimport pandas as pd\nimport numpy as np\nfrom glob import glob\nimport cv2\nimport torchaudio\nfrom torchvision import transforms\nfrom tqdm import tqdm\nimport ffmpeg\n\n# =======================================\n# 1) Load Models\n# =======================================\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n# -------- VIDEO MODEL --------\nimport timm\nimport torch.nn as nn\n\nclass EfficientNetVideoModel(nn.Module):\n    def __init__(self, backbone_name=\"efficientnet_b0\", pretrained=False, num_classes=2):\n        super().__init__()\n        self.backbone = timm.create_model(backbone_name, pretrained=False, num_classes=0)\n        in_features = self.backbone.num_features\n        self.dropout = nn.Dropout(0.15)\n        self.classifier = nn.Linear(in_features, num_classes)\n\n    def forward(self, x):\n        B, T, C, H, W = x.shape\n        x = x.view(B*T, C, H, W)\n        features = self.backbone(x)\n        features = features.view(B, T, -1).mean(dim=1)\n        features = self.dropout(features)\n        logits = self.classifier(features)\n        return logits\n\nVIDEO_MODEL_PATH = \"/kaggle/input/video-model-efficentnet-b0/pytorch/default/1/video_efficientnet_b0.pth\"\nvideo_model = EfficientNetVideoModel(pretrained=False, num_classes=2)\nvideo_model.load_state_dict(torch.load(VIDEO_MODEL_PATH, map_location=device))\nvideo_model.eval().to(device)\n\n# -------- METADATA MODEL --------\nMETA_PIPELINE_PATH = \"/kaggle/input/meta-data-model-randomforest/scikitlearn/default/1/metadata_model_pipeline.pkl\"\nwith open(META_PIPELINE_PATH, \"rb\") as f:\n    meta_pipeline = pickle.load(f)\n\n# -------- AUDIO MODEL --------\nfrom transformers import Wav2Vec2ForSequenceClassification, Wav2Vec2FeatureExtractor\nAUDIO_MODEL_DIR = \"/kaggle/input/audio-model-wave2vec/pytorch/default/1\"\naudio_model = Wav2Vec2ForSequenceClassification.from_pretrained(AUDIO_MODEL_DIR).to(device).eval()\nfeature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(AUDIO_MODEL_DIR)\n\n# =======================================\n# 2) Lip Sync Model (placeholder)\n# =======================================\nclass DummyLipSyncModel:\n    def predict(self, frames): return np.random.rand()\n\nlip_sync_model = DummyLipSyncModel()\ndef get_lip_sync_score(video_path):\n    cap = cv2.VideoCapture(video_path)\n    frames = []\n    while True:\n        ret, frame = cap.read()\n        if not ret: break\n        frames.append(cv2.resize(frame, (96, 96)))\n    cap.release()\n    return float(lip_sync_model.predict(np.array(frames))) if frames else 0.0\n\n# =======================================\n# 3) Video Preprocessing\n# =======================================\nvideo_transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Resize((224, 224)),\n])\n\ndef extract_video_frames(video_path, num_frames=16):\n    cap = cv2.VideoCapture(video_path)\n    total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n    idxs = np.linspace(0, total-1, num_frames).astype(int)\n    frames = []\n    for i in idxs:\n        cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n        ok, frame = cap.read()\n        if not ok: continue\n        frames.append(video_transform(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)))\n    cap.release()\n    return torch.stack(frames).unsqueeze(0).to(device) if frames else None\n\n# =======================================\n# 4) Audio Probability\n# =======================================\n# Fast audio extraction using ffmpeg\ndef extract_audio_from_video(video_path, target_sr=16000, max_duration=None):\n    \"\"\"\n    Extract audio from video, convert to mono, resample to target_sr, optionally limit duration.\n    Returns: waveform (numpy array), sample rate\n    \"\"\"\n    with tempfile.NamedTemporaryFile(suffix=\".wav\") as tmpfile:\n        tmp_wav_path = tmpfile.name\n        cmd = [\"ffmpeg\", \"-y\", \"-i\", video_path, \"-ac\", \"1\", \"-ar\", str(target_sr)]\n        if max_duration:\n            cmd += [\"-t\", str(max_duration)]\n        cmd += [tmp_wav_path]\n        subprocess.run(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n        waveform, sr = torchaudio.load(tmp_wav_path)\n        return waveform.squeeze(0).numpy(), sr\n\n\n# New audio probability function\ndef audio_probability(video_path, max_duration=10):\n    \"\"\"\n    Returns Wav2Vec2 probability for 'fake' class.\n    Only uses first max_duration seconds for speed.\n    \"\"\"\n    try:\n        audio, sr = extract_audio_from_video(video_path, max_duration=max_duration)\n        # Convert to torch tensor\n        audio_tensor = torch.tensor(audio, dtype=torch.float32)\n        # Feature extraction\n        inputs = feature_extractor(audio_tensor, sampling_rate=sr, return_tensors=\"pt\")\n        # Forward pass\n        with torch.no_grad():\n            outputs = audio_model(**inputs.to(device))\n            probs = torch.softmax(outputs.logits, dim=1)\n            return float(probs[:, 1].item())\n    except Exception as e:\n        print(f\"Audio processing error for {video_path}: {e}\")\n        return 0.0\n\n# =======================================\n# 5) Metadata Probability\n# =======================================\ndef extract_metadata_features(video_path):\n    try:\n        probe = ffmpeg.probe(video_path)\n        fmt = probe.get('format', {})\n        streams = probe.get('streams', [])\n\n        md = {\"duration\": float(fmt.get(\"duration\",0)),\n              \"overall_bitrate\": int(fmt.get(\"bit_rate\",0)),\n              \"container\": fmt.get(\"format_name\",\"\"),\n              \"v_codec\":\"\", \"v_width\":0, \"v_height\":0, \"v_fps\":0, \"v_bitrate\":0,\n              \"a_codec\":\"\", \"a_bitrate\":0}\n\n        for s in streams:\n            if s[\"codec_type\"]==\"video\":\n                md.update({\"v_codec\":s.get(\"codec_name\",\"\"), \n                           \"v_width\":int(s.get(\"width\",0)),\n                           \"v_height\":int(s.get(\"height\",0)),\n                           \"v_fps\":eval(s.get(\"r_frame_rate\",\"0\")),\n                           \"v_bitrate\":int(s.get(\"bit_rate\",0))})\n            elif s[\"codec_type\"]==\"audio\":\n                md.update({\"a_codec\":s.get(\"codec_name\",\"\"), \n                           \"a_bitrate\":int(s.get(\"bit_rate\",0))})\n\n        eps = 1e-6\n        md[\"bitrate_per_pixel\"] = md[\"v_bitrate\"]/(md[\"v_width\"]*md[\"v_height\"]+eps)\n        md[\"quality_factor\"] = md[\"v_bitrate\"]/(md[\"v_fps\"]+eps)\n        md[\"av_bitrate_ratio\"] = md[\"a_bitrate\"]/(md[\"v_bitrate\"]+eps)\n        md[\"bitrate_duration_ratio\"] = md[\"overall_bitrate\"]/(md[\"duration\"]+eps)\n        md[\"pixel_count\"] = md[\"v_width\"]*md[\"v_height\"]\n\n        return pd.DataFrame([md])\n    except:\n        return None\n\ndef metadata_probability(video_path):\n    features = extract_metadata_features(video_path)\n    return meta_pipeline.predict_proba(features)[0][1] if features is not None else 0.0\n\n# =======================================\n# 6) Process Videos and Save CSV\n# =======================================\nVIDEO_DIR = \"/kaggle/input/fake-ave-celeb/FakeAVCeleb_v1.2/RealVideo-RealAudio\"\nvideo_files = glob(os.path.join(VIDEO_DIR, \"**/*.mp4\"), recursive=True)\nfusion_data = []\n\nfor vf in tqdm(video_files, desc=\"Processing videos\"):\n    filename = os.path.basename(vf)\n\n    # Video\n    frames = extract_video_frames(vf)\n    video_prob = float(torch.softmax(video_model(frames), dim=1)[0][1].item()) if frames is not None else 0.0\n\n    # Audio\n    audio_prob = audio_probability(vf)\n\n    # Metadata\n    meta_prob = metadata_probability(vf)\n\n    # Lip-sync\n    lipsync_score = get_lip_sync_score(vf)\n\n    # True label\n    true_label = 1 if \"fake\" in filename.lower() else 0\n\n    fusion_data.append({\n        \"filename\": filename,\n        \"video_prob\": video_prob,\n        \"audio_prob\": audio_prob,\n        \"meta_prob\": meta_prob,\n        \"lipsync_score\": lipsync_score,\n        \"true_label\": true_label\n    })\n\nfusion_df = pd.DataFrame(fusion_data)\nfusion_df.to_csv(\"fusion_dataset.csv\", index=False)\nprint(\"\\nSaved → fusion_dataset.csv\")'''\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-11T12:46:30.502656Z","iopub.execute_input":"2025-12-11T12:46:30.503067Z","iopub.status.idle":"2025-12-11T12:46:30.518877Z","shell.execute_reply.started":"2025-12-11T12:46:30.503039Z","shell.execute_reply":"2025-12-11T12:46:30.517997Z"}},"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"'# =======================================\\n# 0) Imports\\nimport tempfile\\nimport subprocess\\n# =======================================\\nimport os\\nimport torch\\nimport pickle\\nimport pandas as pd\\nimport numpy as np\\nfrom glob import glob\\nimport cv2\\nimport torchaudio\\nfrom torchvision import transforms\\nfrom tqdm import tqdm\\nimport ffmpeg\\n\\n# =======================================\\n# 1) Load Models\\n# =======================================\\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\\nprint(\"Using device:\", device)\\n\\n# -------- VIDEO MODEL --------\\nimport timm\\nimport torch.nn as nn\\n\\nclass EfficientNetVideoModel(nn.Module):\\n    def __init__(self, backbone_name=\"efficientnet_b0\", pretrained=False, num_classes=2):\\n        super().__init__()\\n        self.backbone = timm.create_model(backbone_name, pretrained=False, num_classes=0)\\n        in_features = self.backbone.num_features\\n        self.dropout = nn.Dropout(0.15)\\n        self.classifier = nn.Linear(in_features, num_classes)\\n\\n    def forward(self, x):\\n        B, T, C, H, W = x.shape\\n        x = x.view(B*T, C, H, W)\\n        features = self.backbone(x)\\n        features = features.view(B, T, -1).mean(dim=1)\\n        features = self.dropout(features)\\n        logits = self.classifier(features)\\n        return logits\\n\\nVIDEO_MODEL_PATH = \"/kaggle/input/video-model-efficentnet-b0/pytorch/default/1/video_efficientnet_b0.pth\"\\nvideo_model = EfficientNetVideoModel(pretrained=False, num_classes=2)\\nvideo_model.load_state_dict(torch.load(VIDEO_MODEL_PATH, map_location=device))\\nvideo_model.eval().to(device)\\n\\n# -------- METADATA MODEL --------\\nMETA_PIPELINE_PATH = \"/kaggle/input/meta-data-model-randomforest/scikitlearn/default/1/metadata_model_pipeline.pkl\"\\nwith open(META_PIPELINE_PATH, \"rb\") as f:\\n    meta_pipeline = pickle.load(f)\\n\\n# -------- AUDIO MODEL --------\\nfrom transformers import Wav2Vec2ForSequenceClassification, Wav2Vec2FeatureExtractor\\nAUDIO_MODEL_DIR = \"/kaggle/input/audio-model-wave2vec/pytorch/default/1\"\\naudio_model = Wav2Vec2ForSequenceClassification.from_pretrained(AUDIO_MODEL_DIR).to(device).eval()\\nfeature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(AUDIO_MODEL_DIR)\\n\\n# =======================================\\n# 2) Lip Sync Model (placeholder)\\n# =======================================\\nclass DummyLipSyncModel:\\n    def predict(self, frames): return np.random.rand()\\n\\nlip_sync_model = DummyLipSyncModel()\\ndef get_lip_sync_score(video_path):\\n    cap = cv2.VideoCapture(video_path)\\n    frames = []\\n    while True:\\n        ret, frame = cap.read()\\n        if not ret: break\\n        frames.append(cv2.resize(frame, (96, 96)))\\n    cap.release()\\n    return float(lip_sync_model.predict(np.array(frames))) if frames else 0.0\\n\\n# =======================================\\n# 3) Video Preprocessing\\n# =======================================\\nvideo_transform = transforms.Compose([\\n    transforms.ToTensor(),\\n    transforms.Resize((224, 224)),\\n])\\n\\ndef extract_video_frames(video_path, num_frames=16):\\n    cap = cv2.VideoCapture(video_path)\\n    total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\\n    idxs = np.linspace(0, total-1, num_frames).astype(int)\\n    frames = []\\n    for i in idxs:\\n        cap.set(cv2.CAP_PROP_POS_FRAMES, i)\\n        ok, frame = cap.read()\\n        if not ok: continue\\n        frames.append(video_transform(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)))\\n    cap.release()\\n    return torch.stack(frames).unsqueeze(0).to(device) if frames else None\\n\\n# =======================================\\n# 4) Audio Probability\\n# =======================================\\n# Fast audio extraction using ffmpeg\\ndef extract_audio_from_video(video_path, target_sr=16000, max_duration=None):\\n    \"\"\"\\n    Extract audio from video, convert to mono, resample to target_sr, optionally limit duration.\\n    Returns: waveform (numpy array), sample rate\\n    \"\"\"\\n    with tempfile.NamedTemporaryFile(suffix=\".wav\") as tmpfile:\\n        tmp_wav_path = tmpfile.name\\n        cmd = [\"ffmpeg\", \"-y\", \"-i\", video_path, \"-ac\", \"1\", \"-ar\", str(target_sr)]\\n        if max_duration:\\n            cmd += [\"-t\", str(max_duration)]\\n        cmd += [tmp_wav_path]\\n        subprocess.run(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\\n        waveform, sr = torchaudio.load(tmp_wav_path)\\n        return waveform.squeeze(0).numpy(), sr\\n\\n\\n# New audio probability function\\ndef audio_probability(video_path, max_duration=10):\\n    \"\"\"\\n    Returns Wav2Vec2 probability for \\'fake\\' class.\\n    Only uses first max_duration seconds for speed.\\n    \"\"\"\\n    try:\\n        audio, sr = extract_audio_from_video(video_path, max_duration=max_duration)\\n        # Convert to torch tensor\\n        audio_tensor = torch.tensor(audio, dtype=torch.float32)\\n        # Feature extraction\\n        inputs = feature_extractor(audio_tensor, sampling_rate=sr, return_tensors=\"pt\")\\n        # Forward pass\\n        with torch.no_grad():\\n            outputs = audio_model(**inputs.to(device))\\n            probs = torch.softmax(outputs.logits, dim=1)\\n            return float(probs[:, 1].item())\\n    except Exception as e:\\n        print(f\"Audio processing error for {video_path}: {e}\")\\n        return 0.0\\n\\n# =======================================\\n# 5) Metadata Probability\\n# =======================================\\ndef extract_metadata_features(video_path):\\n    try:\\n        probe = ffmpeg.probe(video_path)\\n        fmt = probe.get(\\'format\\', {})\\n        streams = probe.get(\\'streams\\', [])\\n\\n        md = {\"duration\": float(fmt.get(\"duration\",0)),\\n              \"overall_bitrate\": int(fmt.get(\"bit_rate\",0)),\\n              \"container\": fmt.get(\"format_name\",\"\"),\\n              \"v_codec\":\"\", \"v_width\":0, \"v_height\":0, \"v_fps\":0, \"v_bitrate\":0,\\n              \"a_codec\":\"\", \"a_bitrate\":0}\\n\\n        for s in streams:\\n            if s[\"codec_type\"]==\"video\":\\n                md.update({\"v_codec\":s.get(\"codec_name\",\"\"), \\n                           \"v_width\":int(s.get(\"width\",0)),\\n                           \"v_height\":int(s.get(\"height\",0)),\\n                           \"v_fps\":eval(s.get(\"r_frame_rate\",\"0\")),\\n                           \"v_bitrate\":int(s.get(\"bit_rate\",0))})\\n            elif s[\"codec_type\"]==\"audio\":\\n                md.update({\"a_codec\":s.get(\"codec_name\",\"\"), \\n                           \"a_bitrate\":int(s.get(\"bit_rate\",0))})\\n\\n        eps = 1e-6\\n        md[\"bitrate_per_pixel\"] = md[\"v_bitrate\"]/(md[\"v_width\"]*md[\"v_height\"]+eps)\\n        md[\"quality_factor\"] = md[\"v_bitrate\"]/(md[\"v_fps\"]+eps)\\n        md[\"av_bitrate_ratio\"] = md[\"a_bitrate\"]/(md[\"v_bitrate\"]+eps)\\n        md[\"bitrate_duration_ratio\"] = md[\"overall_bitrate\"]/(md[\"duration\"]+eps)\\n        md[\"pixel_count\"] = md[\"v_width\"]*md[\"v_height\"]\\n\\n        return pd.DataFrame([md])\\n    except:\\n        return None\\n\\ndef metadata_probability(video_path):\\n    features = extract_metadata_features(video_path)\\n    return meta_pipeline.predict_proba(features)[0][1] if features is not None else 0.0\\n\\n# =======================================\\n# 6) Process Videos and Save CSV\\n# =======================================\\nVIDEO_DIR = \"/kaggle/input/fake-ave-celeb/FakeAVCeleb_v1.2/RealVideo-RealAudio\"\\nvideo_files = glob(os.path.join(VIDEO_DIR, \"**/*.mp4\"), recursive=True)\\nfusion_data = []\\n\\nfor vf in tqdm(video_files, desc=\"Processing videos\"):\\n    filename = os.path.basename(vf)\\n\\n    # Video\\n    frames = extract_video_frames(vf)\\n    video_prob = float(torch.softmax(video_model(frames), dim=1)[0][1].item()) if frames is not None else 0.0\\n\\n    # Audio\\n    audio_prob = audio_probability(vf)\\n\\n    # Metadata\\n    meta_prob = metadata_probability(vf)\\n\\n    # Lip-sync\\n    lipsync_score = get_lip_sync_score(vf)\\n\\n    # True label\\n    true_label = 1 if \"fake\" in filename.lower() else 0\\n\\n    fusion_data.append({\\n        \"filename\": filename,\\n        \"video_prob\": video_prob,\\n        \"audio_prob\": audio_prob,\\n        \"meta_prob\": meta_prob,\\n        \"lipsync_score\": lipsync_score,\\n        \"true_label\": true_label\\n    })\\n\\nfusion_df = pd.DataFrame(fusion_data)\\nfusion_df.to_csv(\"fusion_dataset.csv\", index=False)\\nprint(\"\\nSaved → fusion_dataset.csv\")'"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install ffmpeg-python\n# =======================================\n# 0) Imports\nimport tempfile\nimport subprocess\n# =======================================\nimport os\nimport torch\nimport pickle\nimport pandas as pd\nimport numpy as np\nfrom glob import glob\nimport cv2\nimport torchaudio\nfrom torchvision import transforms\nfrom tqdm import tqdm\nimport ffmpeg\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T19:55:32.551969Z","iopub.execute_input":"2025-12-25T19:55:32.552198Z","iopub.status.idle":"2025-12-25T19:55:45.002969Z","shell.execute_reply.started":"2025-12-25T19:55:32.552173Z","shell.execute_reply":"2025-12-25T19:55:45.002150Z"}},"outputs":[{"name":"stdout","text":"Collecting ffmpeg-python\n  Downloading ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\nRequirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from ffmpeg-python) (1.0.0)\nDownloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\nInstalling collected packages: ffmpeg-python\nSuccessfully installed ffmpeg-python-0.2.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## ============================\n# CELL 2: Common imports + PATHS\n# ============================\n\nimport os\nimport sys\nimport cv2\nimport torch\nimport torchaudio\nimport numpy as np\nimport pandas as pd\nimport pickle\n\nfrom torch import nn\nfrom torchvision import transforms\nimport timm\n\nfrom transformers import (\n    Wav2Vec2FeatureExtractor,\n    Wav2Vec2ForSequenceClassification\n)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n# ---- Tumhare teen trained models ke paths ----\nVIDEO_MODEL_WEIGHTS_PATH = \"/kaggle/input/video-model-efficentnet-b0/pytorch/default/1/video_efficientnet_b0.pth\"\nAUDIO_MODEL_DIR          = \"/kaggle/input/audio-model-wave2vec/pytorch/default/1\"  # folder jahan HF model files hain\nMETA_MODEL_PATH          = \"/kaggle/input/meta-data-model-randomforest/scikitlearn/default/1/metadata_model_pipeline.pkl\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T19:56:00.696640Z","iopub.execute_input":"2025-12-25T19:56:00.697467Z","iopub.status.idle":"2025-12-25T19:56:26.365860Z","shell.execute_reply.started":"2025-12-25T19:56:00.697425Z","shell.execute_reply":"2025-12-25T19:56:26.365034Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n2025-12-25 19:56:09.746434: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1766692569.935678      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1766692569.992780      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os, hashlib, subprocess\n\nAUDIO_CACHE_DIR = \"/kaggle/working/audio_cache\"\nos.makedirs(AUDIO_CACHE_DIR, exist_ok=True)\n\ndef _cached_wav_path(video_path: str, target_sr: int) -> str:\n    key = hashlib.md5((video_path + f\"_{target_sr}\").encode()).hexdigest()\n    return os.path.join(AUDIO_CACHE_DIR, f\"{key}_{target_sr}.wav\")\n\ndef extract_audio_once(video_path: str, target_sr: int = 16000, timeout_sec: int = 12):\n    \"\"\"\n    Extract audio ONCE per video per sample-rate, store in /kaggle/working/audio_cache.\n    - If cached wav exists, reuse it (no ffmpeg call).\n    - If ffmpeg fails/hangs (timeout), return None.\n    \"\"\"\n    wav_path = _cached_wav_path(video_path, target_sr)\n\n    # reuse if already cached & looks valid\n    if os.path.exists(wav_path) and os.path.getsize(wav_path) > 1024:\n        return wav_path\n\n    cmd = [\n        \"ffmpeg\", \"-y\",\n        \"-probesize\", \"16M\",\n        \"-analyzeduration\", \"16M\",\n        \"-i\", video_path,\n        \"-vn\",\n        \"-ac\", \"1\",\n        \"-ar\", str(target_sr),\n        \"-f\", \"wav\",\n        \"-loglevel\", \"error\",\n        wav_path\n    ]\n\n    try:\n        r = subprocess.run(\n            cmd,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            text=True,\n            timeout=timeout_sec\n        )\n\n        if r.returncode != 0 or (not os.path.exists(wav_path)) or os.path.getsize(wav_path) < 1024:\n            if os.path.exists(wav_path):\n                os.remove(wav_path)\n            return None\n\n        return wav_path\n\n    except subprocess.TimeoutExpired:\n        if os.path.exists(wav_path):\n            os.remove(wav_path)\n        return None\n    except Exception:\n        if os.path.exists(wav_path):\n            os.remove(wav_path)\n        return None\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T19:57:01.236950Z","iopub.execute_input":"2025-12-25T19:57:01.237972Z","iopub.status.idle":"2025-12-25T19:57:01.245052Z","shell.execute_reply.started":"2025-12-25T19:57:01.237944Z","shell.execute_reply":"2025-12-25T19:57:01.244365Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"CELL 3 — VIDEO model (EfficientNet-B0) ka pura code","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# ============================\n# CELL 3: VIDEO MODEL (EfficientNet-B0)\n#   - labels: 0 = real, 1 = fake\n# ============================\n\nclass EfficientNetVideoModel(nn.Module):\n    def __init__(self, backbone_name=\"efficientnet_b0\", pretrained=False, num_classes=2):\n        super().__init__()\n\n        self.backbone = timm.create_model(\n            backbone_name,\n            pretrained=pretrained,\n            num_classes=0  # remove classifier\n        )\n        in_features = self.backbone.num_features\n\n        self.dropout = nn.Dropout(0.15)\n        self.classifier = nn.Linear(in_features, num_classes)\n\n    def forward(self, x):\n        # x shape: [B, T, C, H, W]\n        B, T, C, H, W = x.shape\n        x = x.view(B * T, C, H, W)\n        feats = self.backbone(x)          # [B*T, F]\n        feats = feats.view(B, T, -1)      # [B, T, F]\n        feats = feats.mean(dim=1)         # [B, F]\n        feats = self.dropout(feats)\n        logits = self.classifier(feats)   # [B, 2]\n        return logits\n\n\n# ---- load trained weights ----\nvideo_model = EfficientNetVideoModel(\n    backbone_name=\"efficientnet_b0\",\n    pretrained=False,\n    num_classes=2\n)\n\nstate_dict = torch.load(VIDEO_MODEL_WEIGHTS_PATH, map_location=device)\nvideo_model.load_state_dict(state_dict)\nvideo_model.to(device)\nvideo_model.eval()\n\n# ---- same style transform as training ----\nvideo_transform = transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(\n        mean=[0.485, 0.456, 0.406],\n        std=[0.229, 0.224, 0.225],\n    ),\n])\n\n\ndef _load_video_frames(video_path, num_frames=20, img_size=224):\n    \"\"\"\n    Video se 'num_frames' evenly-spaced frames nikalta hai.\n    \"\"\"\n    cap = cv2.VideoCapture(video_path)\n\n    if not cap.isOpened():\n        return [np.zeros((img_size, img_size, 3), dtype=np.uint8) for _ in range(num_frames)]\n\n    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n    frame_count = max(frame_count, num_frames)\n    indices = np.linspace(0, frame_count - 1, num_frames, dtype=int)\n    idx_set = set(indices.tolist())\n\n    frames = []\n    current = 0\n    while True:\n        ret, frame = cap.read()\n        if not ret:\n            break\n        if current in idx_set:\n            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n            frames.append(frame)\n        current += 1\n\n    cap.release()\n\n    if len(frames) < num_frames:\n        last = frames[-1] if len(frames) > 0 else np.zeros((img_size, img_size, 3), dtype=np.uint8)\n        while len(frames) < num_frames:\n            frames.append(last)\n\n    return frames[:num_frames]\n\n\ndef get_video_prob(video_path, num_frames=20):\n    \"\"\"\n    Output: P(fake | video) -> [0..1]\n    \"\"\"\n    frames = _load_video_frames(video_path, num_frames=num_frames, img_size=224)\n    frame_tensors = [video_transform(f) for f in frames]\n    frames_tensor = torch.stack(frame_tensors, dim=0)       # [T, C, H, W]\n    frames_tensor = frames_tensor.unsqueeze(0).to(device)   # [1, T, C, H, W]\n\n    with torch.no_grad():\n        logits = video_model(frames_tensor)                 # [1, 2]\n        probs  = torch.softmax(logits, dim=1)\n        prob_fake = probs[0, 1].item()                      # class 1 = fake\n\n    return prob_fake\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T19:57:08.207113Z","iopub.execute_input":"2025-12-25T19:57:08.207522Z","iopub.status.idle":"2025-12-25T19:57:08.732386Z","shell.execute_reply.started":"2025-12-25T19:57:08.207497Z","shell.execute_reply":"2025-12-25T19:57:08.731798Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#CELL 4 — AUDIO model (Wav2Vec2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T09:09:00.000364Z","iopub.execute_input":"2025-12-25T09:09:00.001025Z","iopub.status.idle":"2025-12-25T09:09:00.005149Z","shell.execute_reply.started":"2025-12-25T09:09:00.000998Z","shell.execute_reply":"2025-12-25T09:09:00.004489Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# ============================\n# CELL 4: AUDIO MODEL (Wav2Vec2) - CACHED AUDIO (FFmpeg once)\n#   - labels: 0 = real, 1 = fake\n#   - mp4 -> ffmpeg -> wav cached\n#   - if no audio / fail => 0.5 + status\n# ============================\n\nimport os, subprocess, tempfile\nimport torch\nimport torchaudio\nfrom transformers import Wav2Vec2FeatureExtractor, Wav2Vec2ForSequenceClassification\n\naudio_feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(AUDIO_MODEL_DIR)\naudio_model = Wav2Vec2ForSequenceClassification.from_pretrained(AUDIO_MODEL_DIR)\naudio_model.to(device)\naudio_model.eval()\n\n\ndef _ffprobe_has_audio(video_path):\n    \"\"\"\n    True if mp4 has an audio stream, else False\n    \"\"\"\n    cmd = [\n        \"ffprobe\", \"-v\", \"error\",\n        \"-select_streams\", \"a:0\",\n        \"-show_entries\", \"stream=codec_type\",\n        \"-of\", \"default=nw=1:nk=1\",\n        video_path\n    ]\n    try:\n        r = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n        out = (r.stdout or \"\").strip().lower()\n        return (\"audio\" in out)\n    except Exception:\n        return False\n\n\ndef _extract_audio_to_wav(video_path, target_sr=16000, timeout_sec=12):\n    \"\"\"\n    ✅ CACHED VERSION:\n    Extract audio from video -> cached wav (mono, target_sr)\n    Returns wav_path OR None\n    \"\"\"\n    return extract_audio_once(video_path, target_sr=target_sr, timeout_sec=timeout_sec)\n\n\ndef _preprocess_audio_for_wav2vec(video_path, max_length_sec=4):\n    \"\"\"\n    Returns:\n      inputs (dict) OR None if fallback\n      status (dict): tells if audio existed / extracted / fallback\n    \"\"\"\n    status = {\n        \"audio_present\": None,\n        \"extracted_ok\": False,\n        \"used_fallback_0_5\": False,\n        \"reason\": None,     # 'no_audio_stream' / 'ffmpeg_timeout_or_failed' / None\n        \"method\": None,     # 'ffmpeg->wav_cached' / 'fallback'\n        \"error\": None\n    }\n\n    has_audio = _ffprobe_has_audio(video_path)\n    status[\"audio_present\"] = bool(has_audio)\n\n    if not has_audio:\n        status[\"used_fallback_0_5\"] = True\n        status[\"reason\"] = \"no_audio_stream\"\n        status[\"method\"] = \"fallback\"\n        return None, status\n\n    try:\n        wav_path = _extract_audio_to_wav(video_path, target_sr=16000, timeout_sec=12)\n\n        if wav_path is None:\n            status[\"used_fallback_0_5\"] = True\n            status[\"reason\"] = \"ffmpeg_timeout_or_failed\"\n            status[\"method\"] = \"fallback\"\n            return None, status\n\n        status[\"method\"] = \"ffmpeg->wav_cached\"\n        status[\"extracted_ok\"] = True\n\n        audio, sr = torchaudio.load(wav_path)  # cached wav\n\n        # audio shape: [C, T]\n        if audio.ndim > 1:\n            audio = audio.mean(dim=0)\n        audio = audio.squeeze(0)\n\n        if sr != 16000:\n            audio = torchaudio.transforms.Resample(sr, 16000)(audio)\n\n        max_length = 16000 * max_length_sec\n        if len(audio) > max_length:\n            audio = audio[:max_length]\n        else:\n            pad_len = max_length - len(audio)\n            audio = torch.nn.functional.pad(audio, (0, pad_len))\n\n        inputs = audio_feature_extractor(\n            audio.numpy(),\n            sampling_rate=16000,\n            return_tensors=\"pt\",\n            padding=True\n        )\n        inputs = {k: v.to(device) for k, v in inputs.items()}\n        return inputs, status\n\n    except Exception as e:\n        status[\"used_fallback_0_5\"] = True\n        status[\"reason\"] = \"decode_failed\"\n        status[\"method\"] = \"fallback\"\n        status[\"error\"] = repr(e)\n        return None, status\n\n\ndef get_audio_prob_and_status(video_path):\n    \"\"\"\n    Output:\n      prob_fake (float)\n      status (dict)\n    \"\"\"\n    inputs, status = _preprocess_audio_for_wav2vec(video_path)\n\n    if inputs is None:\n        return 0.5, status  # fallback\n\n    with torch.no_grad():\n        outputs = audio_model(**inputs)\n        logits  = outputs.logits\n        probs   = torch.softmax(logits, dim=-1)\n        prob_fake = probs[0, 1].item()\n\n    return float(prob_fake), status\n\n\ndef get_audio_prob(video_path):\n    prob, _ = get_audio_prob_and_status(video_path)\n    return prob\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T19:57:16.917737Z","iopub.execute_input":"2025-12-25T19:57:16.918079Z","iopub.status.idle":"2025-12-25T19:57:19.922442Z","shell.execute_reply.started":"2025-12-25T19:57:16.918053Z","shell.execute_reply":"2025-12-25T19:57:19.921800Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"#CELL 5 — METADATA model (RandomForest pipeline)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T17:25:33.168735Z","iopub.execute_input":"2025-12-25T17:25:33.169042Z","iopub.status.idle":"2025-12-25T17:25:33.172733Z","shell.execute_reply.started":"2025-12-25T17:25:33.169018Z","shell.execute_reply":"2025-12-25T17:25:33.172147Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"import ffmpeg\n\n# yeh wohi fields hain jo humnay  training me use ki thin\nnumeric_features = [\n    \"duration\", \"overall_bitrate\", \"v_width\", \"v_height\", \"v_fps\",\n    \"v_bitrate\", \"a_bitrate\", \"bitrate_per_pixel\", \"quality_factor\",\n    \"av_bitrate_ratio\", \"bitrate_duration_ratio\", \"pixel_count\"\n]\n\ncategorical_features = [\"container\", \"v_codec\", \"a_codec\"]\n\nall_meta_features = numeric_features + categorical_features\n\ndef extract_metadata_from_video(video_path):\n    \"\"\"\n    1 video file se wohi metadata features nikalta hai\n    jo humnay  training me use kiye the.\n    Return: dict(feature_name -> value)\n    \"\"\"\n    try:\n        probe = ffmpeg.probe(video_path)\n        format_info = probe.get('format', {})\n        streams = probe.get('streams', [])\n\n        md = {\n            'duration': float(format_info.get('duration', 0.0)),\n            'overall_bitrate': float(format_info.get('bit_rate', 0.0)),\n            'container': format_info.get('format_name', '') or '',\n            'v_codec': '',\n            'v_width': 0.0,\n            'v_height': 0.0,\n            'v_fps': 0.0,\n            'v_bitrate': 0.0,\n            'a_codec': '',\n            'a_bitrate': 0.0,\n        }\n\n        for stream in streams:\n            if stream.get('codec_type') == 'video':\n                md['v_codec'] = stream.get('codec_name', '') or ''\n                md['v_width'] = float(stream.get('width', 0) or 0)\n                md['v_height'] = float(stream.get('height', 0) or 0)\n\n                fps_str = stream.get('r_frame_rate', '0')\n                try:\n                    md['v_fps'] = float(eval(fps_str)) if fps_str != '0' else 0.0\n                except Exception:\n                    md['v_fps'] = 0.0\n\n                md['v_bitrate'] = float(stream.get('bit_rate', 0.0) or 0.0)\n\n            elif stream.get('codec_type') == 'audio':\n                md['a_codec'] = stream.get('codec_name', '') or ''\n                md['a_bitrate'] = float(stream.get('bit_rate', 0.0) or 0.0)\n\n        # ---- derived features (same as training code) ----\n        eps = 1e-6\n        w = md['v_width']\n        h = md['v_height']\n        vb = md['v_bitrate']\n        ab = md['a_bitrate']\n        ob = md['overall_bitrate']\n        dur = md['duration']\n        fps = md['v_fps']\n\n        pixel_count = w * h\n        bitrate_per_pixel = vb / (pixel_count + eps)\n        quality_factor = vb / (fps + eps)\n        av_bitrate_ratio = ab / (vb + eps)\n        bitrate_duration_ratio = ob / (dur + eps)\n\n        md.update({\n            'pixel_count': pixel_count,\n            'bitrate_per_pixel': bitrate_per_pixel,\n            'quality_factor': quality_factor,\n            'av_bitrate_ratio': av_bitrate_ratio,\n            'bitrate_duration_ratio': bitrate_duration_ratio,\n        })\n\n        # sirf wohi features return karo jo model ko chahiye\n        final_md = {k: md.get(k, 0) for k in all_meta_features}\n        return final_md\n\n    except Exception as e:\n        print(f\"[Metadata] Error processing {video_path}: {e}\")\n        return None\nimport pickle\n\nwith open(META_MODEL_PATH, \"rb\") as f:\n    meta_model = pickle.load(f)   # yeh wahi Pipeline + RandomForest hai\n\ndef get_metadata_prob_from_video(video_path):\n    \"\"\"\n    Directly:\n      video_path -> ffmpeg features -> metadata model -> P(fake)\n    \"\"\"\n    md = extract_metadata_from_video(video_path)\n    if md is None:\n        return 0.5\n\n    df = pd.DataFrame([md])   # 1-row DataFrame with same cols as training\n    proba = meta_model.predict_proba(df)[0, 1]  # class 1 = fake\n    return float(proba)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T19:57:27.580898Z","iopub.execute_input":"2025-12-25T19:57:27.581190Z","iopub.status.idle":"2025-12-25T19:57:27.979130Z","shell.execute_reply.started":"2025-12-25T19:57:27.581166Z","shell.execute_reply":"2025-12-25T19:57:27.978561Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"#LIP-SYNC MODEL \n!pip install -q numba==0.55.1 llvmlite==0.38.1\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T19:57:35.050974Z","iopub.execute_input":"2025-12-25T19:57:35.051550Z","iopub.status.idle":"2025-12-25T19:57:36.776209Z","shell.execute_reply.started":"2025-12-25T19:57:35.051527Z","shell.execute_reply":"2025-12-25T19:57:36.775359Z"}},"outputs":[{"name":"stdout","text":"\u001b[31mERROR: Ignored the following versions that require a different python version: 0.52.0 Requires-Python >=3.6,<3.9; 0.52.0rc3 Requires-Python >=3.6,<3.9; 0.53.0 Requires-Python >=3.6,<3.10; 0.53.0rc1.post1 Requires-Python >=3.6,<3.10; 0.53.0rc2 Requires-Python >=3.6,<3.10; 0.53.0rc3 Requires-Python >=3.6,<3.10; 0.53.1 Requires-Python >=3.6,<3.10; 0.54.0 Requires-Python >=3.7,<3.10; 0.54.0rc2 Requires-Python >=3.7,<3.10; 0.54.0rc3 Requires-Python >=3.7,<3.10; 0.54.1 Requires-Python >=3.7,<3.10; 0.55.0 Requires-Python >=3.7,<3.11; 0.55.0rc1 Requires-Python >=3.7,<3.11; 0.55.1 Requires-Python >=3.7,<3.11; 0.55.2 Requires-Python >=3.7,<3.11\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement numba==0.55.1 (from versions: 0.1, 0.2, 0.3, 0.5.0, 0.6.0, 0.7.0, 0.7.1, 0.7.2, 0.8.0, 0.8.1, 0.9.0, 0.10.0, 0.10.1, 0.11.0, 0.12.0, 0.12.1, 0.12.2, 0.13.0, 0.13.2, 0.13.3, 0.13.4, 0.14.0, 0.15.1, 0.16.0, 0.17.0, 0.18.1, 0.18.2, 0.19.1, 0.19.2, 0.20.0, 0.21.0, 0.22.0, 0.22.1, 0.23.0, 0.23.1, 0.24.0, 0.25.0, 0.26.0, 0.27.0, 0.28.1, 0.29.0, 0.30.0, 0.30.1, 0.31.0, 0.32.0, 0.33.0, 0.34.0, 0.35.0, 0.36.1, 0.36.2, 0.37.0, 0.38.0, 0.38.1, 0.39.0, 0.40.0, 0.40.1, 0.41.0, 0.42.0, 0.42.1, 0.43.0, 0.43.1, 0.44.0, 0.44.1, 0.45.0, 0.45.1, 0.46.0, 0.47.0, 0.48.0, 0.49.0, 0.49.1rc1, 0.49.1, 0.50.0rc1, 0.50.0, 0.50.1, 0.51.0rc1, 0.51.0, 0.51.1, 0.51.2, 0.52.0rc2, 0.56.0rc1, 0.56.0, 0.56.2, 0.56.3, 0.56.4, 0.57.0rc1, 0.57.0, 0.57.1rc1, 0.57.1, 0.58.0rc1, 0.58.0rc2, 0.58.0, 0.58.1, 0.59.0rc1, 0.59.0, 0.59.1, 0.60.0rc1, 0.60.0, 0.61.0rc1, 0.61.0rc2, 0.61.0, 0.61.1rc1, 0.61.2, 0.62.0rc1, 0.62.0rc2, 0.62.0, 0.62.1, 0.63.0b1, 0.63.0rc1, 0.63.0, 0.63.1)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for numba==0.55.1\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# === AV sync / lipsync model dependencies ===\n!pip install -q openl3 librosa soundfile\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T19:57:38.943703Z","iopub.execute_input":"2025-12-25T19:57:38.944031Z","iopub.status.idle":"2025-12-25T19:58:16.699013Z","shell.execute_reply.started":"2025-12-25T19:57:38.944002Z","shell.execute_reply":"2025-12-25T19:58:16.698071Z"}},"outputs":[{"name":"stdout","text":"  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.4/323.4 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m87.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.9/319.9 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Building wheel for openl3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for resampy (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ngoogle-cloud-translate 3.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.29.5 which is incompatible.\nmkl-umath 0.1.1 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.0.2 which is incompatible.\nmkl-random 1.2.4 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.0.2 which is incompatible.\nmkl-fft 1.3.8 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.0.2 which is incompatible.\ndatasets 4.4.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\nray 2.51.1 requires click!=8.3.0,>=7.0, but you have click 8.3.0 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\ngoogle-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\ngoogle-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.4 which is incompatible.\npydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.3 which is incompatible.\npydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\nimbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\numap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.2.2 which is incompatible.\ngcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# ============================================================\n# LIP-SYNC MODEL (OpenL3 AV embeddings) - OPTIMIZED\n# ------------------------------------------------------------\n# Fix: OpenL3 models are loaded ONCE and reused for each video.\n# This prevents re-loading / rebuilding TF model repeatedly.\n# ============================================================\n\nimport openl3\nimport librosa\nimport numpy as np\nimport cv2\nimport tempfile\nimport subprocess\nimport os\n\n# ------------------------------------------------------------\n# 0) GLOBAL OpenL3 MODEL CACHE (load once, reuse everywhere)\n# ------------------------------------------------------------\n_OPENL3_AUDIO_MODEL = None\n_OPENL3_IMAGE_MODEL = None\n\n# Keep these consistent with your current settings\n_OPENL3_INPUT_REPR = \"mel256\"\n_OPENL3_CONTENT_TYPE = \"music\"    # you used \"music\" (ok for now)\n_OPENL3_EMB_SIZE = 512\n\n\ndef _ensure_openl3_models_loaded():\n    \"\"\"\n    Loads OpenL3 audio+image embedding models once.\n    Subsequent calls reuse the cached models.\n    \"\"\"\n    global _OPENL3_AUDIO_MODEL, _OPENL3_IMAGE_MODEL\n\n    if _OPENL3_AUDIO_MODEL is None:\n        _OPENL3_AUDIO_MODEL = openl3.models.load_audio_embedding_model(\n            input_repr=_OPENL3_INPUT_REPR,\n            content_type=_OPENL3_CONTENT_TYPE,\n            embedding_size=_OPENL3_EMB_SIZE\n        )\n\n    if _OPENL3_IMAGE_MODEL is None:\n        _OPENL3_IMAGE_MODEL = openl3.models.load_image_embedding_model(\n            input_repr=_OPENL3_INPUT_REPR,\n            content_type=_OPENL3_CONTENT_TYPE,\n            embedding_size=_OPENL3_EMB_SIZE\n        )\n\n\n# ------------------------------------------------------------\n# 1) SAFE AUDIO LOADER (FFmpeg → WAV → librosa)\n# ------------------------------------------------------------\n# ----------------------------------------\n# SAFE AUDIO LOADER (FFmpeg → WAV → librosa) WITH TIMEOUT\n# ----------------------------------------\n# ----------------------------------------\n# SAFE AUDIO LOADER for OpenL3 (CACHE → librosa)\n# ----------------------------------------\ndef _load_audio_for_openl3(video_path, target_sr=48000, timeout_sec=12):\n    \"\"\"\n    Uses cached ffmpeg audio extraction (one-time per video per SR).\n    Returns: (audio_np, sr) or (None, None)\n    \"\"\"\n    try:\n        wav_path = extract_audio_once(video_path, target_sr=target_sr, timeout_sec=timeout_sec)\n        if wav_path is None:\n            return None, None\n\n        audio, sr = librosa.load(wav_path, sr=target_sr, mono=True)\n        if audio is None or audio.size == 0:\n            return None, None\n\n        return audio, sr\n    except Exception:\n        return None, None\n\n\n# ------------------------------------------------------------\n# 2) SAFE VIDEO FRAMES LOADER\n# ------------------------------------------------------------\ndef _load_video_frames_for_openl3(video_path, num_frames=8):\n    \"\"\"\n    Loads uniformly sampled frames, resized to 224x224 RGB float32 [0,1].\n    Returns: (frames, fps)\n      frames shape: [num_frames, 224, 224, 3]\n    \"\"\"\n    cap = cv2.VideoCapture(video_path)\n\n    # fallback FPS\n    fallback_fps = 25.0\n\n    if not cap.isOpened():\n        frames = np.zeros((num_frames, 224, 224, 3), dtype=np.float32)\n        return frames, fallback_fps\n\n    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT) or 0)\n    fps = float(cap.get(cv2.CAP_PROP_FPS) or 0)\n    if fps <= 1.0:\n        fps = fallback_fps\n\n    # choose indices evenly across the clip\n    if frame_count <= 0:\n        indices = np.arange(num_frames)\n    else:\n        indices = np.linspace(0, max(frame_count - 1, 0), num_frames).astype(int)\n\n    idx_set = set(indices.tolist())\n    frames = []\n    index = 0\n\n    while True:\n        ret, frame = cap.read()\n        if not ret:\n            break\n        if index in idx_set:\n            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n            frame = cv2.resize(frame, (224, 224))\n            frames.append(frame)\n        index += 1\n\n    cap.release()\n\n    # if no frames extracted -> fallback zeros\n    if len(frames) == 0:\n        frames = np.zeros((num_frames, 224, 224, 3), dtype=np.float32)\n        return frames, fps\n\n    # pad frames to num_frames (repeat last)\n    last = frames[-1]\n    while len(frames) < num_frames:\n        frames.append(last)\n\n    frames = np.stack(frames[:num_frames], axis=0).astype(np.float32) / 255.0\n    return frames, fps\n\n\n# ------------------------------------------------------------\n# 3) FINAL LIP-SYNC PROBABILITY (OpenL3, model cached)\n# ------------------------------------------------------------\ndef get_lipsync_prob_avsync(video_path):\n    \"\"\"\n    Returns: P(fake | lipsync) in [0,1]\n      - Uses OpenL3 audio + image embeddings\n      - Computes cosine similarity between mean audio and mean video embeddings\n      - sync = (cos_sim + 1) / 2  in [0,1]\n      - returns 1 - sync  (higher => more mismatch => more \"fake\")\n    \"\"\"\n    try:\n        # Ensure models are loaded ONCE\n        _ensure_openl3_models_loaded()\n\n        # ----- AUDIO -----\n        audio, sr = _load_audio_for_openl3(video_path, target_sr=48000)\n        if audio is None:\n            return 0.5\n\n        a_emb, _ = openl3.get_audio_embedding(\n            audio,\n            sr,\n            model=_OPENL3_AUDIO_MODEL,          # ✅ REUSE MODEL\n            input_repr=_OPENL3_INPUT_REPR,\n            content_type=_OPENL3_CONTENT_TYPE,\n            embedding_size=_OPENL3_EMB_SIZE,\n            center=True,\n            hop_size=1.0,\n            batch_size=4,\n            verbose=False\n        )\n        a_vec = a_emb.mean(axis=0)\n\n        # ----- VIDEO -----\n        frames, fps = _load_video_frames_for_openl3(video_path, num_frames=8)\n\n        v_emb, _ = openl3.get_image_embedding(\n            frames,\n            frame_rate=fps,\n            model=_OPENL3_IMAGE_MODEL,          # ✅ REUSE MODEL\n            input_repr=_OPENL3_INPUT_REPR,\n            content_type=_OPENL3_CONTENT_TYPE,\n            embedding_size=_OPENL3_EMB_SIZE,\n            batch_size=4,\n            verbose=False\n        )\n        v_vec = v_emb.mean(axis=0)\n\n        # ----- COSINE SIM -----\n        denom = (np.linalg.norm(a_vec) * np.linalg.norm(v_vec) + 1e-8)\n        cos_sim = float(np.dot(a_vec, v_vec) / denom)\n\n        # map [-1,1] to [0,1]\n        sync = (cos_sim + 1.0) / 2.0\n        sync = float(np.clip(sync, 0.0, 1.0))\n\n        # mismatch => fake probability\n        return float(1.0 - sync)\n\n    except Exception as e:\n        print(f\"[AVSync] Error computing lipsync for {video_path}: {repr(e)}\")\n        return 0.5\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T19:58:22.621984Z","iopub.execute_input":"2025-12-25T19:58:22.622293Z","iopub.status.idle":"2025-12-25T19:58:24.065679Z","shell.execute_reply.started":"2025-12-25T19:58:22.622264Z","shell.execute_reply":"2025-12-25T19:58:24.065082Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def weighted_ensemble(video_path):\n    \"\"\"\n    video_path: ek single .mp4 file ka path\n    Sab models khud apna input handle karte hain:\n      - video model: frames\n      - audio model: audio waveform\n      - metadata model: ffmpeg metadata\n      - lipsync model: audio+video sync\n    \"\"\"\n\n    video_p   = get_video_prob(video_path)               # P(fake | video)\n    audio_p   = get_audio_prob(video_path)               # P(fake | audio)\n    meta_p    = get_metadata_prob_from_video(video_path) # P(fake | metadata classifier)\n    lipsync_p = get_lipsync_prob_avsync(video_path)      # P(fake | lipsync)\n\n    final_score = (\n        0.37 * video_p +\n        0.37 * audio_p +\n        0.26 * lipsync_p +\n        0.0 * meta_p\n    )\n\n    final_label = 1 if final_score >= 0.5 else 0  # 1 = fake, 0 = real\n\n    return {\n        \"video_prob_fake\":    video_p,\n        \"audio_prob_fake\":    audio_p,\n        \"metadata_prob_fake\": meta_p,\n        \"lipsync_prob_fake\":  lipsync_p,\n        \"final_score_fake\":   final_score,\n        \"final_label\":        final_label,\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T19:58:33.289630Z","iopub.execute_input":"2025-12-25T19:58:33.290923Z","iopub.status.idle":"2025-12-25T19:58:33.295663Z","shell.execute_reply.started":"2025-12-25T19:58:33.290899Z","shell.execute_reply":"2025-12-25T19:58:33.294942Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"example_video_path = \"/kaggle/input/testing-dataset1/Meta_Data_Dataset/Real_videos/D26_V_outdoorYT_panrot_0002.mp4\"\n\nresult = weighted_ensemble(example_video_path)\nprint(result)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T19:00:38.830376Z","iopub.execute_input":"2025-12-25T19:00:38.830686Z","iopub.status.idle":"2025-12-25T19:00:38.872387Z","shell.execute_reply.started":"2025-12-25T19:00:38.830663Z","shell.execute_reply":"2025-12-25T19:00:38.871503Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_47/565240123.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mexample_video_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/kaggle/input/testing-dataset1/Meta_Data_Dataset/Real_videos/D26_V_outdoorYT_panrot_0002.mp4\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweighted_ensemble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_video_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'weighted_ensemble' is not defined"],"ename":"NameError","evalue":"name 'weighted_ensemble' is not defined","output_type":"error"}],"execution_count":5},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_video = \"/kaggle/input/testing-dataset1/Meta_Data_Dataset/fake_videos/VID-20251204-WA0049.mp4\"  # agar filename different ho to apni list se ek le lo\nprint(test_video)\n\n# direct call (no try/except)\nweighted_ensemble(test_video)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T15:12:58.175182Z","iopub.execute_input":"2025-12-25T15:12:58.175712Z","iopub.status.idle":"2025-12-25T15:12:58.270775Z","shell.execute_reply.started":"2025-12-25T15:12:58.175684Z","shell.execute_reply":"2025-12-25T15:12:58.269918Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/testing-dataset1/Meta_Data_Dataset/fake_videos/VID-20251204-WA0049.mp4\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_47/59143102.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# direct call (no try/except)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mweighted_ensemble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_video\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'weighted_ensemble' is not defined"],"ename":"NameError","evalue":"name 'weighted_ensemble' is not defined","output_type":"error"}],"execution_count":2},{"cell_type":"code","source":"print(os.listdir(AUDIO_MODEL_DIR))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T14:25:02.846839Z","iopub.execute_input":"2025-12-14T14:25:02.847583Z","iopub.status.idle":"2025-12-14T14:25:02.852462Z","shell.execute_reply.started":"2025-12-14T14:25:02.847558Z","shell.execute_reply":"2025-12-14T14:25:02.851844Z"}},"outputs":[{"name":"stdout","text":"['config.json', 'preprocessor_config.json', 'model.safetensors']\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# ============================================================\n# LAV-DF (Localized Audio Visual DeepFake) - Fusion Evaluation\n# ------------------------------------------------------------\n# What this script does:\n# 1) Loads LAV-DF metadata.min.json\n# 2) Builds a balanced 1k subset (500 Real + 500 Fake) from a split\n#    with optional \"easy subset\" filters to improve accuracy.\n# 3) Runs your fusion model: weighted_ensemble(video_path)\n# 4) Prints metrics + plots:\n#    - Accuracy\n#    - Classification report\n#    - Confusion matrix (plot)\n#    - ROC-AUC + ROC curve\n#\n# Requirements:\n# - Your notebook must already define: weighted_ensemble(video_path)\n# - sklearn, matplotlib, tqdm\n# ============================================================\n\nimport os\nimport json\nimport random\nimport numpy as np\nfrom tqdm import tqdm\n\nfrom sklearn.metrics import (\n    accuracy_score,\n    classification_report,\n    confusion_matrix,\n    roc_auc_score,\n    roc_curve\n)\nimport matplotlib.pyplot as plt\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T11:25:23.551712Z","iopub.execute_input":"2025-12-25T11:25:23.552059Z","iopub.status.idle":"2025-12-25T11:25:23.556721Z","shell.execute_reply.started":"2025-12-25T11:25:23.552037Z","shell.execute_reply":"2025-12-25T11:25:23.556053Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# 0) CONFIG: Set your dataset paths here (you already provided)\n# ============================================================\n\nLAVDF_ROOT = \"/kaggle/input/localized-audio-visual-deepfake-dataset-lav-df/LAV-DF\"\nTEST_DIR   = \"/kaggle/input/localized-audio-visual-deepfake-dataset-lav-df/LAV-DF/test\"\nMETADATA_PATH = \"/kaggle/input/localized-audio-visual-deepfake-dataset-lav-df/LAV-DF/metadata.min.json\"\n\nVIDEO_EXTS = (\".mp4\", \".avi\", \".mov\", \".mkv\", \".webm\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T15:04:00.876962Z","iopub.execute_input":"2025-12-25T15:04:00.877545Z","iopub.status.idle":"2025-12-25T15:04:00.881619Z","shell.execute_reply.started":"2025-12-25T15:04:00.877515Z","shell.execute_reply":"2025-12-25T15:04:00.880944Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"THRESHOLD = 0.5  # same as your code\n\ndef weighted_ensemble(video_path, use_metadata: bool = True):\n    # base probs\n    video_p   = get_video_prob(video_path)                 # P(fake|video)\n    audio_p   = get_audio_prob(video_path)                 # P(fake|audio)\n    lipsync_p = get_lipsync_prob_avsync(video_path)        # P(fake|lipsync)\n\n    # meta prob (if metadata is OFF, still compute? -> better: set neutral 0.5)\n    if use_metadata:\n        meta_p = get_metadata_prob_from_video(video_path)  # P(fake|meta)\n        w_video, w_audio, w_lipsync, w_meta = 0.35, 0.35, 0.25, 0.05\n    else:\n        meta_p = 0.5  # neutral, no effect\n        w_video, w_audio, w_lipsync, w_meta = 0.37, 0.37, 0.26, 0.0\n\n    final_score = (\n        w_video   * video_p +\n        w_audio   * audio_p +\n        w_lipsync * lipsync_p +\n        w_meta    * meta_p\n    )\n\n    final_label = 1 if final_score >= THRESHOLD else 0  # 1=fake, 0=real\n\n    return {\n        \"video_prob_fake\":    float(video_p),\n        \"audio_prob_fake\":    float(audio_p),\n        \"metadata_prob_fake\": float(meta_p),\n        \"lipsync_prob_fake\":  float(lipsync_p),\n        \"final_score_fake\":   float(final_score),\n        \"final_label\":        int(final_label),\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T19:58:44.986349Z","iopub.execute_input":"2025-12-25T19:58:44.986609Z","iopub.status.idle":"2025-12-25T19:58:44.991852Z","shell.execute_reply.started":"2025-12-25T19:58:44.986592Z","shell.execute_reply":"2025-12-25T19:58:44.990978Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# ============================================================\n# MIXED DATASET BUILDER (FakeAVCeleb FAKE + LAV-DF REAL)\n#   - Fake: from FakeAVCeleb FakeVideo-FakeAudio\n#   - Real: from LAV-DF metadata where split=test, n_fakes=0, audio present\n# ============================================================\n\nimport os, json, random\n\nFAKE_DIR = \"/kaggle/input/fake-ave-celeb/FakeAVCeleb_v1.2/FakeVideo-FakeAudio\"\n\nLAVDF_ROOT = \"/kaggle/input/localized-audio-visual-deepfake-dataset-lav-df/LAV-DF\"\nLAVDF_TEST_DIR = \"/kaggle/input/localized-audio-visual-deepfake-dataset-lav-df/LAV-DF/test\"\nLAVDF_META = \"/kaggle/input/localized-audio-visual-deepfake-dataset-lav-df/LAV-DF/metadata.min.json\"\n\nVIDEO_EXTS = (\".mp4\", \".avi\", \".mov\", \".mkv\", \".webm\")\n\n\ndef list_videos(folder):\n    vids = []\n    for root, _, files in os.walk(folder):\n        for f in files:\n            if f.lower().endswith(VIDEO_EXTS):\n                vids.append(os.path.join(root, f))\n    return vids\n\n\ndef load_metadata(path):\n    with open(path, \"r\") as f:\n        meta = json.load(f)\n\n    # handle list format\n    if isinstance(meta, list):\n        return meta\n\n    # handle dict format\n    if isinstance(meta, dict):\n        records = []\n        for k, v in meta.items():\n            if isinstance(v, dict):\n                rec = dict(v)\n                rec[\"file\"] = rec.get(\"file\", k)\n                records.append(rec)\n        return records\n\n    raise ValueError(f\"Unsupported metadata format: {type(meta)}\")\n\n\ndef resolve_lavdf_path(file_field: str):\n    \"\"\"\n    metadata file field usually like: \"test/xxxx.mp4\"\n    We try:\n      1) LAVDF_ROOT + file_field\n      2) LAVDF_TEST_DIR + basename(file_field)\n    \"\"\"\n    if not file_field:\n        return None\n\n    p1 = os.path.join(LAVDF_ROOT, file_field)\n    if os.path.exists(p1):\n        return p1\n\n    base = os.path.basename(file_field)\n    p2 = os.path.join(LAVDF_TEST_DIR, base)\n    if os.path.exists(p2):\n        return p2\n\n    return None\n\n\ndef has_audio_from_meta(rec: dict) -> bool:\n    \"\"\"\n    ensures real voice exists in LAV-DF metadata\n    \"\"\"\n    ch = int(rec.get(\"audio_channels\", 0) or 0)\n    fr = int(rec.get(\"audio_frames\", 0) or 0)\n    return (ch > 0) and (fr > 0)\n\n\ndef build_mixed_subset(n_each=150, seed=42):\n    random.seed(seed)\n\n    # --------- Fake videos ----------\n    fake_videos = list_videos(FAKE_DIR)\n    random.shuffle(fake_videos)\n    fake_sel = fake_videos[:n_each]\n\n    # --------- Real videos (LAV-DF) ----------\n    meta = load_metadata(LAVDF_META)\n\n    real_candidates = []\n    for rec in meta:\n        if rec.get(\"split\") != \"test\":\n            continue\n\n        # real condition\n        if int(rec.get(\"n_fakes\", 0) or 0) != 0:\n            continue\n\n        # must have audio\n        if not has_audio_from_meta(rec):\n            continue\n\n        vp = resolve_lavdf_path(rec.get(\"file\"))\n        if vp and vp.lower().endswith(VIDEO_EXTS):\n            real_candidates.append(vp)\n\n    random.shuffle(real_candidates)\n    real_sel = real_candidates[:n_each]\n\n    print(\"Available FAKE (FakeAVCeleb):\", len(fake_videos))\n    print(\"Available REAL (LAV-DF real-only + audio):\", len(real_candidates))\n\n    if len(fake_sel) < n_each:\n        print(\"⚠️ Not enough fake videos found.\")\n        return None\n\n    if len(real_sel) < n_each:\n        print(\"⚠️ Not enough real videos found in LAV-DF with audio.\")\n        return None\n\n    # label: fake=1, real=0\n    data = [(p, 1) for p in fake_sel] + [(p, 0) for p in real_sel]\n    random.shuffle(data)\n\n    print(\"\\n✅ Mixed dataset ready\")\n    print(\"Total:\", len(data), \"| Fake:\", n_each, \"| Real:\", n_each)\n    return data\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T19:59:05.398816Z","iopub.execute_input":"2025-12-25T19:59:05.399343Z","iopub.status.idle":"2025-12-25T19:59:05.411838Z","shell.execute_reply.started":"2025-12-25T19:59:05.399299Z","shell.execute_reply":"2025-12-25T19:59:05.411226Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# ============================================================\n# RESUME / CHECKPOINT EVALUATION (Crash-safe)\n# ------------------------------------------------------------\n# - Saves progress every N videos to /kaggle/working/...\n# - If session off/crash happens, re-run and it RESUMES\n# - Works with your weighted_ensemble(video_path)\n# - Prints final Accuracy, Classification Report, Confusion Matrix + ROC\n# ============================================================\n\nimport os, pickle, gc\nimport numpy as np\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n\nfrom sklearn.metrics import (\n    accuracy_score, classification_report, confusion_matrix,\n    roc_auc_score, roc_curve\n)\n\nCHECKPOINT_PATH = \"/kaggle/working/mixed_eval_checkpoint.pkl\"\n\n\ndef _save_ckpt(path, idx, y_true, y_pred, y_score, failures):\n    with open(path, \"wb\") as f:\n        pickle.dump({\n            \"idx\": idx,\n            \"y_true\": y_true,\n            \"y_pred\": y_pred,\n            \"y_score\": y_score,\n            \"failures\": failures\n        }, f)\n\n\ndef _load_ckpt(path):\n    with open(path, \"rb\") as f:\n        return pickle.load(f)\n\n\ndef plot_confusion_matrix(cm, title=\"Confusion Matrix\"):\n    plt.figure(figsize=(5,4))\n    plt.imshow(cm)\n    plt.title(title)\n    plt.colorbar()\n    plt.xticks([0,1], [\"Real\", \"Fake\"])\n    plt.yticks([0,1], [\"Real\", \"Fake\"])\n\n    for i in range(2):\n        for j in range(2):\n            plt.text(j, i, cm[i,j],\n                     ha=\"center\", va=\"center\",\n                     color=\"white\" if cm[i,j] > cm.max()/2 else \"black\")\n    plt.ylabel(\"True label\")\n    plt.xlabel(\"Predicted label\")\n    plt.tight_layout()\n    plt.show()\n\n\ndef plot_roc_curve(y_true, y_score, title=\"ROC Curve\"):\n    fpr, tpr, _ = roc_curve(y_true, y_score)\n    plt.figure(figsize=(6,4))\n    plt.plot(fpr, tpr)\n    plt.plot([0,1],[0,1],\"--\")\n    plt.title(title)\n    plt.xlabel(\"False Positive Rate\")\n    plt.ylabel(\"True Positive Rate\")\n    plt.tight_layout()\n    plt.show()\n\n\ndef evaluate_fusion_resume(\n    data,\n    checkpoint_path=CHECKPOINT_PATH,\n    save_every=10,\n    heartbeat_every=20,\n    warmup=True\n):\n    \"\"\"\n    data: list of (video_path, label)\n    label: 0=real, 1=fake\n    \"\"\"\n\n    # -------------------------\n    # Resume if checkpoint exists\n    # -------------------------\n    if os.path.exists(checkpoint_path):\n        ckpt = _load_ckpt(checkpoint_path)\n        start_idx = int(ckpt.get(\"idx\", 0))\n        y_true = ckpt.get(\"y_true\", [])\n        y_pred = ckpt.get(\"y_pred\", [])\n        y_score = ckpt.get(\"y_score\", [])\n        failures = ckpt.get(\"failures\", [])\n        print(f\"✅ Resuming from {start_idx}/{len(data)}\")\n    else:\n        start_idx = 0\n        y_true, y_pred, y_score, failures = [], [], [], []\n        print(\"✅ Starting fresh (no checkpoint found)\")\n\n    # -------------------------\n    # Warmup (loads models once)\n    # -------------------------\n    if warmup and start_idx < len(data):\n        try:\n            vp0, _ = data[start_idx]\n            _ = weighted_ensemble(vp0)\n            print(\"✅ Warmup done\")\n        except Exception as e:\n            print(\"⚠️ Warmup failed (continuing):\", repr(e))\n\n    # -------------------------\n    # Main loop\n    # -------------------------\n    for i in tqdm(range(start_idx, len(data)), desc=\"Running fusion (resume-safe)\"):\n        vp, label = data[i]\n\n        try:\n            out = weighted_ensemble(vp)\n            y_true.append(int(label))\n            y_pred.append(int(out[\"final_label\"]))\n            y_score.append(float(out[\"final_score_fake\"]))\n            del out\n        except Exception as e:\n            failures.append((vp, repr(e)))\n\n        # memory cleanup\n        gc.collect()\n\n        # heartbeat log\n        if (i + 1) % heartbeat_every == 0:\n            print(f\"[heartbeat] {i+1}/{len(data)} done | fails={len(failures)}\")\n\n        # save checkpoint\n        if (i + 1) % save_every == 0:\n            _save_ckpt(checkpoint_path, i + 1, y_true, y_pred, y_score, failures)\n\n    # Final save\n    _save_ckpt(checkpoint_path, len(data), y_true, y_pred, y_score, failures)\n\n    # -------------------------\n    # Metrics + plots\n    # -------------------------\n    print(\"\\n================ RESULTS ================\")\n    print(\"Planned:\", len(data))\n    print(\"Processed:\", len(y_true))\n    print(\"Failed:\", len(failures))\n    print(\"Checkpoint:\", checkpoint_path)\n    print(\"========================================\\n\")\n\n    if len(y_true) == 0:\n        print(\"⚠️ No samples processed. First 5 failures:\")\n        for vp, err in failures[:5]:\n            print(vp, \"->\", err)\n        return None\n\n    acc = accuracy_score(y_true, y_pred)\n    print(f\"Accuracy: {acc:.4f}\\n\")\n\n    print(\"Classification Report:\")\n    print(classification_report(y_true, y_pred, target_names=[\"Real(0)\", \"Fake(1)\"]))\n\n    cm = confusion_matrix(y_true, y_pred)\n    print(\"Confusion Matrix:\\n\", cm)\n    plot_confusion_matrix(cm, title=\"Confusion Matrix (Mixed Dataset)\")\n\n    try:\n        auc = roc_auc_score(y_true, y_score)\n        print(\"ROC-AUC:\", round(auc, 4))\n        plot_roc_curve(y_true, y_score, title=\"ROC Curve (Mixed Dataset)\")\n    except Exception as e:\n        print(\"ROC-AUC not available:\", repr(e))\n\n    if failures:\n        print(\"\\nFirst 5 failures:\")\n        for vp, err in failures[:5]:\n            print(vp, \"->\", err)\n\n    return {\n        \"acc\": acc,\n        \"cm\": cm,\n        \"y_true\": y_true,\n        \"y_pred\": y_pred,\n        \"y_score\": y_score,\n        \"failures\": failures,\n        \"checkpoint_path\": checkpoint_path\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T19:59:13.989933Z","iopub.execute_input":"2025-12-25T19:59:13.990500Z","iopub.status.idle":"2025-12-25T19:59:14.007098Z","shell.execute_reply.started":"2025-12-25T19:59:13.990478Z","shell.execute_reply":"2025-12-25T19:59:14.006191Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T16:51:17.224503Z","iopub.execute_input":"2025-12-25T16:51:17.224846Z","iopub.status.idle":"2025-12-25T16:51:17.230801Z","shell.execute_reply.started":"2025-12-25T16:51:17.224821Z","shell.execute_reply":"2025-12-25T16:51:17.229994Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"data800 = build_mixed_subset(n_each=100, seed=42)   # or 400\nmixed_results = evaluate_fusion_resume(\n    data800,\n    checkpoint_path=\"/kaggle/working/mixed_eval_checkpoint.pkl\",\n    save_every=10,\n    heartbeat_every=20,\n    warmup=True\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T19:59:22.358572Z","iopub.execute_input":"2025-12-25T19:59:22.358835Z","iopub.status.idle":"2025-12-25T20:00:38.250721Z","shell.execute_reply.started":"2025-12-25T19:59:22.358815Z","shell.execute_reply":"2025-12-25T20:00:38.249717Z"}},"outputs":[{"name":"stdout","text":"Available FAKE (FakeAVCeleb): 10835\nAvailable REAL (LAV-DF real-only + audio): 6906\n\n✅ Mixed dataset ready\nTotal: 200 | Fake: 100 | Real: 100\n✅ Starting fresh (no checkpoint found)\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1766692789.241590      47 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13168 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1766692789.242337      47 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1766692802.570517     165 service.cc:148] XLA service 0x7ce4a400d5c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1766692802.571092     165 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1766692802.571111     165 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\nI0000 00:00:1766692802.719809     165 cuda_dnn.cc:529] Loaded cuDNN version 90300\nI0000 00:00:1766692807.477188     165 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"✅ Warmup done\n","output_type":"stream"},{"name":"stderr","text":"Running fusion (resume-safe):   2%|▏         | 4/200 [00:07<05:33,  1.70s/it]","output_type":"stream"},{"name":"stdout","text":"[AVSync] Error computing lipsync for /kaggle/input/fake-ave-celeb/FakeAVCeleb_v1.2/FakeVideo-FakeAudio/Caucasian (American)/men/id01096/00037_id00020_wavtolip.mp4: RuntimeError('pybind11::error_already_set: MISMATCH of original and normalized active exception types: ORIGINAL InternalError REPLACED BY KeyboardInterrupt: <EMPTY MESSAGE>\\n\\nAt:\\n  /usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/errors_impl.py(462): __init__\\n  /usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py(53): quick_execute\\n  /usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py(1683): call_function\\n  /usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py(251): call_flat\\n  /usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py(216): call_preflattened\\n  /usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py(1322): _call_flat\\n  /usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py(139): call_function\\n  /usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py(878): _call\\n  /usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py(833): __call__\\n  /usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py(150): error_handler\\n  /usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py(562): predict\\n  /usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py(117): error_handler\\n  /usr/local/lib/python3.11/dist-packages/openl3/core.py(277): get_audio_embedding\\n  /tmp/ipykernel_47/2225286435.py(157): get_lipsync_prob_avsync\\n  /tmp/ipykernel_47/180336344.py(7): weighted_ensemble\\n  /tmp/ipykernel_47/2151361504.py(116): evaluate_fusion_resume\\n  /tmp/ipykernel_47/2083676456.py(2): <cell line: 0>\\n  /usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py(3553): run_code\\n  /usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py(3473): run_ast_nodes\\n  /usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py(3257): run_cell_async\\n  /usr/local/lib/python3.11/dist-packages/IPython/core/async_helpers.py(78): _pseudo_sync_runner\\n  /usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py(3030): _run_cell\\n  /usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py(2975): run_cell\\n  /usr/local/lib/python3.11/dist-packages/ipykernel/zmqshell.py(528): run_cell\\n  /usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py(383): do_execute\\n  /usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py(730): execute_request\\n  /usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py(406): dispatch_shell\\n  /usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py(499): process_one\\n  /usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py(510): dispatch_queue\\n  /usr/lib/python3.11/asyncio/events.py(84): _run\\n  /usr/lib/python3.11/asyncio/base_events.py(1936): _run_once\\n  /usr/lib/python3.11/asyncio/base_events.py(608): run_forever\\n  /usr/local/lib/python3.11/dist-packages/tornado/platform/asyncio.py(211): start\\n  /usr/local/lib/python3.11/dist-packages/ipykernel/kernelapp.py(712): start\\n  /usr/local/lib/python3.11/dist-packages/traitlets/config/application.py(992): launch_instance\\n  /usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py(37): <module>\\n  <frozen runpy>(88): _run_code\\n  <frozen runpy>(198): _run_module_as_main\\n')\n","output_type":"stream"},{"name":"stderr","text":"Running fusion (resume-safe):   6%|▋         | 13/200 [00:21<04:04,  1.31s/it]","output_type":"stream"},{"name":"stdout","text":"[AVSync] Error computing lipsync for /kaggle/input/fake-ave-celeb/FakeAVCeleb_v1.2/FakeVideo-FakeAudio/Caucasian (American)/women/id03556/00043_id01004_867Wlj7Gw68_id00458_wavtolip.mp4: InternalError()\n","output_type":"stream"},{"name":"stderr","text":"Running fusion (resume-safe):   7%|▋         | 14/200 [00:23<05:13,  1.68s/it]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_47/2083676456.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata800\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_mixed_subset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_each\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# or 400\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m mixed_results = evaluate_fusion_resume(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mdata800\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/kaggle/working/mixed_eval_checkpoint.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msave_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_47/2151361504.py\u001b[0m in \u001b[0;36mevaluate_fusion_resume\u001b[0;34m(data, checkpoint_path, save_every, heartbeat_every, warmup)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweighted_ensemble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m             \u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"final_label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_47/180336344.py\u001b[0m in \u001b[0;36mweighted_ensemble\u001b[0;34m(video_path, use_metadata)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mweighted_ensemble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_metadata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# base probs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mvideo_p\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mget_video_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[0;34m)\u001b[0m                 \u001b[0;31m# P(fake|video)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0maudio_p\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mget_audio_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[0;34m)\u001b[0m                 \u001b[0;31m# P(fake|audio)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mlipsync_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_lipsync_prob_avsync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;31m# P(fake|lipsync)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_47/3293226964.py\u001b[0m in \u001b[0;36mget_video_prob\u001b[0;34m(video_path, num_frames)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0mOutput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mvideo\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;36m.1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \"\"\"\n\u001b[0;32m---> 95\u001b[0;31m     \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_video_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_frames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_frames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m     \u001b[0mframe_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvideo_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0mframes_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m       \u001b[0;31m# [T, C, H, W]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_47/3293226964.py\u001b[0m in \u001b[0;36m_load_video_frames\u001b[0;34m(video_path, num_frames, img_size)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mcurrent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":14},{"cell_type":"code","source":"# ============================================================\n# ONE-PASS (FAST) + RESUME/CHECKPOINT\n# Compare:\n#   A) WITHOUT metadata  : video=0.37, audio=0.37, lipsync=0.26, meta=0.00\n#   B) WITH metadata     : video=0.35, audio=0.35, lipsync=0.25, meta=0.05\n# Then run McNemar test to check if metadata significantly improves.\n# ------------------------------------------------------------\n# ✅ Computes heavy parts (OpenL3 lipsync etc.) ONCE per video\n# ✅ Saves checkpoint every N videos\n# ✅ Resume from last checkpoint after session off/crash\n# ✅ Outputs:\n#    - Acc(no-meta), Acc(with-meta)\n#    - Confusion matrices\n#    - McNemar (b,c,p-value) + decision\n# ============================================================\n\nimport os, pickle, gc\nimport numpy as np\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n\nfrom sklearn.metrics import (\n    accuracy_score, classification_report, confusion_matrix\n)\nfrom statsmodels.stats.contingency_tables import mcnemar\n\n\n# =========================\n# SETTINGS\n# =========================\nTHRESHOLD = 0.5\n\n# IMPORTANT: keep dataset order fixed (load saved data list if you have)\nDATA_PATH = \"/kaggle/working/mixed_data_fixed.pkl\"          # <-- optional but recommended\nCKPT_PATH = \"/kaggle/working/meta_ablation_ckpt.pkl\"        # checkpoint for predictions\n\nSAVE_EVERY = 10\nHEARTBEAT_EVERY = 20\n\n\n# =========================\n# OPTIONAL: Fix dataset order\n# =========================\ndef get_or_save_data(build_fn, n_each=150, seed=42, data_path=DATA_PATH):\n    \"\"\"\n    Ensures data order is identical across resumes.\n    build_fn must return list[(video_path, label)].\n    \"\"\"\n    if os.path.exists(data_path):\n        with open(data_path, \"rb\") as f:\n            data = pickle.load(f)\n        print(\"✅ Loaded saved data:\", len(data))\n        return data\n\n    data = build_fn(n_each=n_each, seed=seed)\n    if data is None:\n        return None\n\n    with open(data_path, \"wb\") as f:\n        pickle.dump(data, f)\n    print(\"✅ Saved data:\", len(data))\n    return data\n\n\n# =========================\n# ONE-PASS predictor\n# =========================\ndef predict_two_versions_one_pass(video_path):\n    \"\"\"\n    Computes base probs ONCE, returns:\n      score_no_meta, pred_no_meta, score_with_meta, pred_with_meta\n    \"\"\"\n    video_p   = get_video_prob(video_path)\n    audio_p   = get_audio_prob(video_path)\n    lipsync_p = get_lipsync_prob_avsync(video_path)\n    meta_p    = get_metadata_prob_from_video(video_path)\n\n    # A) WITHOUT metadata (exact weights you gave)\n    score_no = (\n        0.37 * video_p +\n        0.37 * audio_p +\n        0.26 * lipsync_p +\n        0.00 * meta_p\n    )\n    pred_no = 1 if score_no >= THRESHOLD else 0\n\n    # B) WITH metadata (exact weights you gave)\n    score_m = (\n        0.35 * video_p +\n        0.35 * audio_p +\n        0.25 * lipsync_p +\n        0.05 * meta_p\n    )\n    pred_m = 1 if score_m >= THRESHOLD else 0\n\n    return float(score_no), int(pred_no), float(score_m), int(pred_m)\n\n\n# =========================\n# CHECKPOINT SAVE/LOAD\n# =========================\ndef _save_ckpt(path, idx, y_true, p0, p1, s0, s1, failures):\n    with open(path, \"wb\") as f:\n        pickle.dump({\n            \"idx\": idx,\n            \"y_true\": y_true,\n            \"y_pred_no_meta\": p0,\n            \"y_pred_with_meta\": p1,\n            \"y_score_no_meta\": s0,\n            \"y_score_with_meta\": s1,\n            \"failures\": failures\n        }, f)\n\ndef _load_ckpt(path):\n    with open(path, \"rb\") as f:\n        return pickle.load(f)\n\n\n# =========================\n# PLOTS\n# =========================\ndef plot_confusion_matrix(cm, title):\n    plt.figure(figsize=(5,4))\n    plt.imshow(cm)\n    plt.title(title)\n    plt.colorbar()\n    plt.xticks([0,1], [\"Real\", \"Fake\"])\n    plt.yticks([0,1], [\"Real\", \"Fake\"])\n    for i in range(2):\n        for j in range(2):\n            plt.text(j, i, cm[i,j],\n                     ha=\"center\", va=\"center\",\n                     color=\"white\" if cm[i,j] > cm.max()/2 else \"black\")\n    plt.ylabel(\"True\")\n    plt.xlabel(\"Pred\")\n    plt.tight_layout()\n    plt.show()\n\n\n# =========================\n# MAIN: RUN + RESUME\n# =========================\ndef run_meta_ablation_with_resume(data, ckpt_path=CKPT_PATH):\n    \"\"\"\n    data = list of (video_path, label)\n    label: 0=real, 1=fake\n    \"\"\"\n    if data is None or len(data) == 0:\n        print(\"⚠️ Empty data. Stop.\")\n        return None\n\n    # Resume if exists\n    if os.path.exists(ckpt_path):\n        ckpt = _load_ckpt(ckpt_path)\n        start_idx = int(ckpt.get(\"idx\", 0))\n\n        y_true = ckpt.get(\"y_true\", [])\n        y_pred_no = ckpt.get(\"y_pred_no_meta\", [])\n        y_pred_m  = ckpt.get(\"y_pred_with_meta\", [])\n        y_score_no = ckpt.get(\"y_score_no_meta\", [])\n        y_score_m  = ckpt.get(\"y_score_with_meta\", [])\n        failures = ckpt.get(\"failures\", [])\n\n        print(f\"✅ Resuming from {start_idx}/{len(data)} | fails={len(failures)}\")\n    else:\n        start_idx = 0\n        y_true, y_pred_no, y_pred_m, y_score_no, y_score_m, failures = [], [], [], [], [], []\n        print(\"✅ Starting fresh (no checkpoint found)\")\n\n    # Warmup (loads models once)\n    if start_idx < len(data):\n        try:\n            vp0, _ = data[start_idx]\n            _ = predict_two_versions_one_pass(vp0)\n            print(\"✅ Warmup done\")\n        except Exception as e:\n            print(\"⚠️ Warmup failed (continuing):\", repr(e))\n\n    # Loop\n    for i in tqdm(range(start_idx, len(data)), desc=\"Meta Ablation (one-pass + resume)\"):\n        vp, label = data[i]\n        try:\n            s0, p0, s1, p1 = predict_two_versions_one_pass(vp)\n\n            y_true.append(int(label))\n            y_pred_no.append(int(p0))\n            y_pred_m.append(int(p1))\n            y_score_no.append(float(s0))\n            y_score_m.append(float(s1))\n\n        except Exception as e:\n            failures.append((vp, repr(e)))\n\n        gc.collect()\n\n        if (i + 1) % HEARTBEAT_EVERY == 0:\n            print(f\"[heartbeat] {i+1}/{len(data)} done | fails={len(failures)}\")\n\n        if (i + 1) % SAVE_EVERY == 0:\n            _save_ckpt(ckpt_path, i + 1, y_true, y_pred_no, y_pred_m, y_score_no, y_score_m, failures)\n\n    # Final save\n    _save_ckpt(ckpt_path, len(data), y_true, y_pred_no, y_pred_m, y_score_no, y_score_m, failures)\n\n    # =========================\n    # METRICS\n    # =========================\n    print(\"\\n================ RESULTS ================\")\n    print(\"Planned:\", len(data))\n    print(\"Processed:\", len(y_true))\n    print(\"Failed:\", len(failures))\n    print(\"Checkpoint:\", ckpt_path)\n    print(\"========================================\\n\")\n\n    if len(y_true) == 0:\n        print(\"⚠️ Nothing processed. First 5 failures:\")\n        for vp, err in failures[:5]:\n            print(vp, \"->\", err)\n        return None\n\n    acc_no = accuracy_score(y_true, y_pred_no)\n    acc_m  = accuracy_score(y_true, y_pred_m)\n\n    print(f\"Accuracy (NO metadata) : {acc_no:.4f}\")\n    print(f\"Accuracy (WITH metadata): {acc_m:.4f}\\n\")\n\n    print(\"Classification Report (NO metadata):\")\n    print(classification_report(y_true, y_pred_no, target_names=[\"Real(0)\", \"Fake(1)\"]))\n\n    print(\"Classification Report (WITH metadata):\")\n    print(classification_report(y_true, y_pred_m, target_names=[\"Real(0)\", \"Fake(1)\"]))\n\n    cm_no = confusion_matrix(y_true, y_pred_no)\n    cm_m  = confusion_matrix(y_true, y_pred_m)\n\n    print(\"Confusion Matrix (NO metadata):\\n\", cm_no)\n    print(\"Confusion Matrix (WITH metadata):\\n\", cm_m)\n\n    plot_confusion_matrix(cm_no, \"Confusion Matrix (NO metadata)\")\n    plot_confusion_matrix(cm_m,  \"Confusion Matrix (WITH metadata)\")\n\n    # =========================\n    # McNemar TEST\n    # =========================\n    b = 0  # no-meta correct, meta wrong\n    c = 0  # no-meta wrong, meta correct\n\n    for yt, p0, p1 in zip(y_true, y_pred_no, y_pred_m):\n        no_ok = (p0 == yt)\n        me_ok = (p1 == yt)\n        if no_ok and not me_ok:\n            b += 1\n        elif (not no_ok) and me_ok:\n            c += 1\n\n    table = [[0, b],\n             [c, 0]]\n\n    res = mcnemar(table, exact=False, correction=True)\n\n    print(\"\\n=========== McNemar Test ===========\")\n    print(\"b (no-meta correct, meta wrong):\", b)\n    print(\"c (no-meta wrong, meta correct):\", c)\n    print(\"Net gain (c-b):\", c - b)\n    print(\"p-value:\", res.pvalue)\n\n    if res.pvalue < 0.05:\n        print(\"✅ Significant improvement with metadata (reject H0)\")\n    else:\n        print(\"❌ Not significant (fail to reject H0)\")\n    print(\"====================================\\n\")\n\n    if failures:\n        print(\"First 5 failures:\")\n        for vp, err in failures[:5]:\n            print(vp, \"->\", err)\n\n    return {\n        \"acc_no_meta\": acc_no,\n        \"acc_with_meta\": acc_m,\n        \"cm_no_meta\": cm_no,\n        \"cm_with_meta\": cm_m,\n        \"b\": b,\n        \"c\": c,\n        \"p_value\": res.pvalue,\n        \"y_true\": y_true,\n        \"y_pred_no_meta\": y_pred_no,\n        \"y_pred_with_meta\": y_pred_m,\n        \"y_score_no_meta\": y_score_no,\n        \"y_score_with_meta\": y_score_m,\n        \"failures\": failures,\n        \"ckpt_path\": ckpt_path\n    }\n\n\n# ============================================================\n# RUN (put this at the end)\n# ============================================================\n# 1) Make sure you already have build_mixed_subset() defined in your notebook.\n\ndata_fixed = get_or_save_data(build_mixed_subset, n_each=100, seed=42, data_path=DATA_PATH)\n\nresults = run_meta_ablation_with_resume(data_fixed, ckpt_path=CKPT_PATH)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T20:02:01.460929Z","iopub.execute_input":"2025-12-25T20:02:01.461563Z","iopub.status.idle":"2025-12-25T20:08:19.835513Z","shell.execute_reply.started":"2025-12-25T20:02:01.461541Z","shell.execute_reply":"2025-12-25T20:08:19.834770Z"}},"outputs":[{"name":"stdout","text":"✅ Loaded saved data: 300\n✅ Resuming from 10/300 | fails=0\n[AVSync] Error computing lipsync for /kaggle/input/localized-audio-visual-deepfake-dataset-lav-df/LAV-DF/test/077218.mp4: InternalError()\n✅ Warmup done\n","output_type":"stream"},{"name":"stderr","text":"Meta Ablation (one-pass + resume):   0%|          | 0/290 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"[AVSync] Error computing lipsync for /kaggle/input/localized-audio-visual-deepfake-dataset-lav-df/LAV-DF/test/077218.mp4: InternalError()\n","output_type":"stream"},{"name":"stderr","text":"Meta Ablation (one-pass + resume):   1%|          | 2/290 [00:02<05:36,  1.17s/it]","output_type":"stream"},{"name":"stdout","text":"[AVSync] Error computing lipsync for /kaggle/input/fake-ave-celeb/FakeAVCeleb_v1.2/FakeVideo-FakeAudio/African/men/id01597/00005_2_id02040_wavtolip.mp4: InternalError()\n","output_type":"stream"},{"name":"stderr","text":"Meta Ablation (one-pass + resume):   2%|▏         | 6/290 [00:06<05:10,  1.09s/it]","output_type":"stream"},{"name":"stdout","text":"[AVSync] Error computing lipsync for /kaggle/input/fake-ave-celeb/FakeAVCeleb_v1.2/FakeVideo-FakeAudio/Caucasian (European)/men/id00519/00028_id01058_2DKbOjf3Wyo_id00498_wavtolip.mp4: InternalError()\n","output_type":"stream"},{"name":"stderr","text":"Meta Ablation (one-pass + resume):   3%|▎         | 10/290 [00:11<05:28,  1.17s/it]","output_type":"stream"},{"name":"stdout","text":"[heartbeat] 20/300 done | fails=0\n[AVSync] Error computing lipsync for /kaggle/input/fake-ave-celeb/FakeAVCeleb_v1.2/FakeVideo-FakeAudio/Caucasian (American)/women/id03707/00055_id00458_wavtolip.mp4: InternalError()\n","output_type":"stream"},{"name":"stderr","text":"Meta Ablation (one-pass + resume):   4%|▍         | 12/290 [00:14<05:34,  1.20s/it]","output_type":"stream"},{"name":"stdout","text":"[AVSync] Error computing lipsync for /kaggle/input/localized-audio-visual-deepfake-dataset-lav-df/LAV-DF/test/046175.mp4: InternalError()\n","output_type":"stream"},{"name":"stderr","text":"Meta Ablation (one-pass + resume):  10%|▉         | 28/290 [00:34<05:13,  1.20s/it]","output_type":"stream"},{"name":"stdout","text":"[AVSync] Error computing lipsync for /kaggle/input/fake-ave-celeb/FakeAVCeleb_v1.2/FakeVideo-FakeAudio/Asian (South)/women/id07008/00175_id05434_6p7kCmdOjDQ_faceswap_id04070_wavtolip.mp4: InternalError()\n","output_type":"stream"},{"name":"stderr","text":"Meta Ablation (one-pass + resume):  10%|█         | 30/290 [00:36<05:32,  1.28s/it]","output_type":"stream"},{"name":"stdout","text":"[heartbeat] 40/300 done | fails=0\n","output_type":"stream"},{"name":"stderr","text":"Meta Ablation (one-pass + resume):  11%|█         | 31/290 [00:38<05:28,  1.27s/it]","output_type":"stream"},{"name":"stdout","text":"[AVSync] Error computing lipsync for /kaggle/input/localized-audio-visual-deepfake-dataset-lav-df/LAV-DF/test/125463.mp4: InternalError()\n","output_type":"stream"},{"name":"stderr","text":"Meta Ablation (one-pass + resume):  13%|█▎        | 39/290 [00:48<05:16,  1.26s/it]","output_type":"stream"},{"name":"stdout","text":"[AVSync] Error computing lipsync for /kaggle/input/localized-audio-visual-deepfake-dataset-lav-df/LAV-DF/test/046130.mp4: InternalError()\n","output_type":"stream"},{"name":"stderr","text":"Meta Ablation (one-pass + resume):  15%|█▌        | 44/290 [00:54<05:10,  1.26s/it]","output_type":"stream"},{"name":"stdout","text":"[AVSync] Error computing lipsync for /kaggle/input/fake-ave-celeb/FakeAVCeleb_v1.2/FakeVideo-FakeAudio/Caucasian (American)/women/id00261/00048_id01227_eNr-P3gIrgo_id01005_wavtolip.mp4: InternalError()\n","output_type":"stream"},{"name":"stderr","text":"Meta Ablation (one-pass + resume):  16%|█▌        | 45/290 [00:56<05:29,  1.34s/it]","output_type":"stream"},{"name":"stdout","text":"[AVSync] Error computing lipsync for /kaggle/input/localized-audio-visual-deepfake-dataset-lav-df/LAV-DF/test/046604.mp4: InternalError()\n","output_type":"stream"},{"name":"stderr","text":"Meta Ablation (one-pass + resume):  17%|█▋        | 50/290 [01:03<05:12,  1.30s/it]","output_type":"stream"},{"name":"stdout","text":"[heartbeat] 60/300 done | fails=0\n[AVSync] Error computing lipsync for /kaggle/input/fake-ave-celeb/FakeAVCeleb_v1.2/FakeVideo-FakeAudio/Asian (South)/women/id00488/00028_id00080_wavtolip.mp4: InternalError()\n","output_type":"stream"},{"name":"stderr","text":"Meta Ablation (one-pass + resume):  21%|██        | 61/290 [01:17<04:42,  1.23s/it]","output_type":"stream"},{"name":"stdout","text":"[AVSync] Error computing lipsync for /kaggle/input/localized-audio-visual-deepfake-dataset-lav-df/LAV-DF/test/077003.mp4: InternalError()\n","output_type":"stream"},{"name":"stderr","text":"Meta Ablation (one-pass + resume):  22%|██▏       | 64/290 [01:21<04:48,  1.28s/it]","output_type":"stream"},{"name":"stdout","text":"[AVSync] Error computing lipsync for /kaggle/input/localized-audio-visual-deepfake-dataset-lav-df/LAV-DF/test/130676.mp4: InternalError()\n","output_type":"stream"},{"name":"stderr","text":"Meta Ablation (one-pass + resume):  24%|██▍       | 69/290 [01:27<04:37,  1.26s/it]","output_type":"stream"},{"name":"stdout","text":"[AVSync] Error computing lipsync for /kaggle/input/localized-audio-visual-deepfake-dataset-lav-df/LAV-DF/test/126907.mp4: InternalError()\n","output_type":"stream"},{"name":"stderr","text":"Meta Ablation (one-pass + resume):  24%|██▍       | 70/290 [01:29<05:06,  1.39s/it]","output_type":"stream"},{"name":"stdout","text":"[heartbeat] 80/300 done | fails=0\n[AVSync] Error computing lipsync for /kaggle/input/localized-audio-visual-deepfake-dataset-lav-df/LAV-DF/test/022644.mp4: InternalError()\n","output_type":"stream"},{"name":"stderr","text":"Meta Ablation (one-pass + resume):  25%|██▌       | 73/290 [01:33<04:49,  1.33s/it]","output_type":"stream"},{"name":"stdout","text":"[AVSync] Error computing lipsync for /kaggle/input/fake-ave-celeb/FakeAVCeleb_v1.2/FakeVideo-FakeAudio/Asian (East)/women/id03211/00032_id02587_wavtolip.mp4: InternalError()\n","output_type":"stream"},{"name":"stderr","text":"Meta Ablation (one-pass + resume):  26%|██▌       | 76/290 [01:37<04:40,  1.31s/it]","output_type":"stream"},{"name":"stdout","text":"[AVSync] Error computing lipsync for /kaggle/input/localized-audio-visual-deepfake-dataset-lav-df/LAV-DF/test/075965.mp4: InternalError()\n","output_type":"stream"},{"name":"stderr","text":"Meta Ablation (one-pass + resume):  28%|██▊       | 81/290 [01:43<04:29,  1.29s/it]","output_type":"stream"},{"name":"stdout","text":"[AVSync] Error computing lipsync for /kaggle/input/fake-ave-celeb/FakeAVCeleb_v1.2/FakeVideo-FakeAudio/Caucasian (American)/men/id01096/00037_id00020_wavtolip.mp4: InternalError()\n","output_type":"stream"},{"name":"stderr","text":"Meta Ablation (one-pass + resume):  29%|██▉       | 84/290 [01:47<04:24,  1.29s/it]","output_type":"stream"},{"name":"stdout","text":"[AVSync] Error computing lipsync for /kaggle/input/localized-audio-visual-deepfake-dataset-lav-df/LAV-DF/test/001025.mp4: InternalError()\n","output_type":"stream"},{"name":"stderr","text":"Meta Ablation (one-pass + resume):  29%|██▉       | 85/290 [01:49<04:42,  1.38s/it]","output_type":"stream"},{"name":"stdout","text":"[AVSync] Error computing lipsync for /kaggle/input/localized-audio-visual-deepfake-dataset-lav-df/LAV-DF/test/064008.mp4: InternalError()\n","output_type":"stream"},{"name":"stderr","text":"Meta Ablation (one-pass + resume):  31%|███       | 90/290 [01:55<04:18,  1.29s/it]","output_type":"stream"},{"name":"stdout","text":"[heartbeat] 100/300 done | fails=0\n","output_type":"stream"},{"name":"stderr","text":"Meta Ablation (one-pass + resume):  33%|███▎      | 97/290 [02:04<03:59,  1.24s/it]","output_type":"stream"},{"name":"stdout","text":"[AVSync] Error computing lipsync for /kaggle/input/localized-audio-visual-deepfake-dataset-lav-df/LAV-DF/test/001832.mp4: InternalError()\n","output_type":"stream"},{"name":"stderr","text":"Meta Ablation (one-pass + resume):  34%|███▍      | 100/290 [02:08<04:05,  1.29s/it]","output_type":"stream"},{"name":"stdout","text":"[AVSync] Error computing lipsync for /kaggle/input/fake-ave-celeb/FakeAVCeleb_v1.2/FakeVideo-FakeAudio/Caucasian (European)/men/id01052/00076_id00548_DXbYU3qhN7U_id00520_wavtolip.mp4: InternalError()\n","output_type":"stream"},{"name":"stderr","text":"Meta Ablation (one-pass + resume):  35%|███▍      | 101/290 [02:10<04:15,  1.35s/it]","output_type":"stream"},{"name":"stdout","text":"[AVSync] Error computing lipsync for /kaggle/input/fake-ave-celeb/FakeAVCeleb_v1.2/FakeVideo-FakeAudio/Asian (South)/women/id07051/00083_id05435_OvX-Jv_whcU_id00488_wavtolip.mp4: InternalError()\n","output_type":"stream"},{"name":"stderr","text":"Meta Ablation (one-pass + resume):  35%|███▌      | 102/290 [02:11<04:26,  1.41s/it]","output_type":"stream"},{"name":"stdout","text":"[AVSync] Error computing lipsync for /kaggle/input/localized-audio-visual-deepfake-dataset-lav-df/LAV-DF/test/131766.mp4: InternalError()\n","output_type":"stream"},{"name":"stderr","text":"Meta Ablation (one-pass + resume):  38%|███▊      | 110/290 [02:22<04:00,  1.34s/it]","output_type":"stream"},{"name":"stdout","text":"[heartbeat] 120/300 done | fails=0\n","output_type":"stream"},{"name":"stderr","text":"Meta Ablation (one-pass + resume):  38%|███▊      | 111/290 [02:23<03:56,  1.32s/it]","output_type":"stream"},{"name":"stdout","text":"[AVSync] Error computing lipsync for /kaggle/input/localized-audio-visual-deepfake-dataset-lav-df/LAV-DF/test/003552.mp4: InternalError()\n","output_type":"stream"},{"name":"stderr","text":"Meta Ablation (one-pass + resume):  44%|████▍     | 129/290 [02:46<03:24,  1.27s/it]","output_type":"stream"},{"name":"stdout","text":"[AVSync] Error computing lipsync for /kaggle/input/localized-audio-visual-deepfake-dataset-lav-df/LAV-DF/test/044762.mp4: InternalError()\n","output_type":"stream"},{"name":"stderr","text":"Meta Ablation (one-pass + resume):  45%|████▍     | 130/290 [02:48<03:39,  1.37s/it]","output_type":"stream"},{"name":"stdout","text":"[heartbeat] 140/300 done | fails=0\n","output_type":"stream"},{"name":"stderr","text":"Meta Ablation (one-pass + resume):  49%|████▊     | 141/290 [03:02<03:07,  1.26s/it]","output_type":"stream"},{"name":"stdout","text":"[AVSync] Error computing lipsync for /kaggle/input/fake-ave-celeb/FakeAVCeleb_v1.2/FakeVideo-FakeAudio/Asian (East)/women/id07383/00011_id06462_Nn79kE76MA4_id07799_wavtolip.mp4: InternalError()\n","output_type":"stream"},{"name":"stderr","text":"Meta Ablation (one-pass + resume):  52%|█████▏    | 150/290 [03:13<02:52,  1.23s/it]","output_type":"stream"},{"name":"stdout","text":"[heartbeat] 160/300 done | fails=0\n[AVSync] Error computing lipsync for /kaggle/input/localized-audio-visual-deepfake-dataset-lav-df/LAV-DF/test/125889.mp4: InternalError()\n","output_type":"stream"},{"name":"stderr","text":"Meta Ablation (one-pass + resume):  52%|█████▏    | 152/290 [03:16<02:59,  1.30s/it]","output_type":"stream"},{"name":"stdout","text":"[AVSync] Error computing lipsync for /kaggle/input/localized-audio-visual-deepfake-dataset-lav-df/LAV-DF/test/022085.mp4: InternalError()\n","output_type":"stream"},{"name":"stderr","text":"Meta Ablation (one-pass + resume):  53%|█████▎    | 155/290 [03:20<02:48,  1.25s/it]","output_type":"stream"},{"name":"stdout","text":"[AVSync] Error computing lipsync for /kaggle/input/localized-audio-visual-deepfake-dataset-lav-df/LAV-DF/test/009777.mp4: InternalError()\n","output_type":"stream"},{"name":"stderr","text":"Meta Ablation (one-pass + resume):  56%|█████▌    | 162/290 [03:29<02:42,  1.27s/it]","output_type":"stream"},{"name":"stdout","text":"[AVSync] Error computing lipsync for /kaggle/input/localized-audio-visual-deepfake-dataset-lav-df/LAV-DF/test/091413.mp4: InternalError()\n","output_type":"stream"},{"name":"stderr","text":"Meta Ablation (one-pass + resume):  58%|█████▊    | 168/290 [03:37<02:33,  1.26s/it]","output_type":"stream"},{"name":"stdout","text":"[AVSync] Error computing lipsync for /kaggle/input/localized-audio-visual-deepfake-dataset-lav-df/LAV-DF/test/012845.mp4: InternalError()\n","output_type":"stream"},{"name":"stderr","text":"Meta Ablation (one-pass + resume):  59%|█████▊    | 170/290 [03:40<02:36,  1.31s/it]","output_type":"stream"},{"name":"stdout","text":"[heartbeat] 180/300 done | fails=0\n","output_type":"stream"},{"name":"stderr","text":"Meta Ablation (one-pass + resume):  60%|█████▉    | 173/290 [03:44<02:34,  1.32s/it]","output_type":"stream"},{"name":"stdout","text":"[AVSync] Error computing lipsync for /kaggle/input/localized-audio-visual-deepfake-dataset-lav-df/LAV-DF/test/041535.mp4: InternalError()\n","output_type":"stream"},{"name":"stderr","text":"Meta Ablation (one-pass + resume):  61%|██████    | 177/290 [03:49<02:29,  1.32s/it]","output_type":"stream"},{"name":"stdout","text":"[AVSync] Error computing lipsync for /kaggle/input/fake-ave-celeb/FakeAVCeleb_v1.2/FakeVideo-FakeAudio/Caucasian (European)/men/id00185/00015_id00594_2WHHoksbeVw_id00187_wavtolip.mp4: InternalError()\n","output_type":"stream"},{"name":"stderr","text":"Meta Ablation (one-pass + resume):  62%|██████▏   | 181/290 [03:54<02:14,  1.24s/it]","output_type":"stream"},{"name":"stdout","text":"[AVSync] Error computing lipsync for /kaggle/input/fake-ave-celeb/FakeAVCeleb_v1.2/FakeVideo-FakeAudio/Caucasian (American)/men/id00264/00257_2_id01124_wavtolip.mp4: InternalError()\n","output_type":"stream"},{"name":"stderr","text":"Meta Ablation (one-pass + resume):  63%|██████▎   | 183/290 [03:57<02:15,  1.27s/it]","output_type":"stream"},{"name":"stdout","text":"[AVSync] Error computing lipsync for /kaggle/input/localized-audio-visual-deepfake-dataset-lav-df/LAV-DF/test/129785.mp4: InternalError()\n","output_type":"stream"},{"name":"stderr","text":"Meta Ablation (one-pass + resume):  65%|██████▍   | 188/290 [04:03<02:06,  1.24s/it]","output_type":"stream"},{"name":"stdout","text":"[AVSync] Error computing lipsync for /kaggle/input/fake-ave-celeb/FakeAVCeleb_v1.2/FakeVideo-FakeAudio/Caucasian (European)/men/id01099/00206_id00559_Y7ovoKuvL78_id00498_wavtolip.mp4: InternalError()\n","output_type":"stream"},{"name":"stderr","text":"Meta Ablation (one-pass + resume):  66%|██████▌   | 190/290 [04:06<02:08,  1.28s/it]","output_type":"stream"},{"name":"stdout","text":"[heartbeat] 200/300 done | fails=0\n","output_type":"stream"},{"name":"stderr","text":"Meta Ablation (one-pass + resume):  66%|██████▌   | 191/290 [04:07<02:05,  1.26s/it]","output_type":"stream"},{"name":"stdout","text":"[AVSync] Error computing lipsync for /kaggle/input/fake-ave-celeb/FakeAVCeleb_v1.2/FakeVideo-FakeAudio/Caucasian (European)/men/id00185/00015_id00171_PWU6n0qrv4c_id00368_wavtolip.mp4: InternalError()\n","output_type":"stream"},{"name":"stderr","text":"Meta Ablation (one-pass + resume):  67%|██████▋   | 194/290 [04:11<02:04,  1.29s/it]","output_type":"stream"},{"name":"stdout","text":"[AVSync] Error computing lipsync for /kaggle/input/localized-audio-visual-deepfake-dataset-lav-df/LAV-DF/test/021976.mp4: InternalError()\n","output_type":"stream"},{"name":"stderr","text":"Meta Ablation (one-pass + resume):  72%|███████▏  | 210/290 [04:31<01:37,  1.22s/it]","output_type":"stream"},{"name":"stdout","text":"[heartbeat] 220/300 done | fails=0\n","output_type":"stream"},{"name":"stderr","text":"Meta Ablation (one-pass + resume):  75%|███████▌  | 218/290 [04:41<01:28,  1.23s/it]","output_type":"stream"},{"name":"stdout","text":"[AVSync] Error computing lipsync for /kaggle/input/localized-audio-visual-deepfake-dataset-lav-df/LAV-DF/test/077827.mp4: InternalError()\n","output_type":"stream"},{"name":"stderr","text":"Meta Ablation (one-pass + resume):  78%|███████▊  | 226/290 [04:51<01:19,  1.24s/it]","output_type":"stream"},{"name":"stdout","text":"[AVSync] Error computing lipsync for /kaggle/input/localized-audio-visual-deepfake-dataset-lav-df/LAV-DF/test/045820.mp4: InternalError()\n","output_type":"stream"},{"name":"stderr","text":"Meta Ablation (one-pass + resume):  79%|███████▉  | 230/290 [04:57<01:17,  1.30s/it]","output_type":"stream"},{"name":"stdout","text":"[heartbeat] 240/300 done | fails=0\n","output_type":"stream"},{"name":"stderr","text":"Meta Ablation (one-pass + resume):  80%|███████▉  | 231/290 [04:58<01:14,  1.27s/it]","output_type":"stream"},{"name":"stdout","text":"[AVSync] Error computing lipsync for /kaggle/input/localized-audio-visual-deepfake-dataset-lav-df/LAV-DF/test/131844.mp4: InternalError()\n","output_type":"stream"},{"name":"stderr","text":"Meta Ablation (one-pass + resume):  80%|████████  | 233/290 [05:01<01:14,  1.31s/it]","output_type":"stream"},{"name":"stdout","text":"[AVSync] Error computing lipsync for /kaggle/input/localized-audio-visual-deepfake-dataset-lav-df/LAV-DF/test/077870.mp4: InternalError()\n","output_type":"stream"},{"name":"stderr","text":"Meta Ablation (one-pass + resume):  81%|████████▏ | 236/290 [05:05<01:11,  1.32s/it]","output_type":"stream"},{"name":"stdout","text":"[AVSync] Error computing lipsync for /kaggle/input/fake-ave-celeb/FakeAVCeleb_v1.2/FakeVideo-FakeAudio/African/women/id05235/00052_id02508_wavtolip.mp4: InternalError()\n","output_type":"stream"},{"name":"stderr","text":"Meta Ablation (one-pass + resume):  85%|████████▍ | 246/290 [05:18<00:55,  1.27s/it]","output_type":"stream"},{"name":"stdout","text":"[AVSync] Error computing lipsync for /kaggle/input/localized-audio-visual-deepfake-dataset-lav-df/LAV-DF/test/007392.mp4: InternalError()\n","output_type":"stream"},{"name":"stderr","text":"Meta Ablation (one-pass + resume):  86%|████████▌ | 248/290 [05:21<00:55,  1.32s/it]","output_type":"stream"},{"name":"stdout","text":"[AVSync] Error computing lipsync for /kaggle/input/localized-audio-visual-deepfake-dataset-lav-df/LAV-DF/test/027200.mp4: InternalError()\n","output_type":"stream"},{"name":"stderr","text":"Meta Ablation (one-pass + resume):  86%|████████▌ | 250/290 [05:23<00:54,  1.37s/it]","output_type":"stream"},{"name":"stdout","text":"[heartbeat] 260/300 done | fails=0\n","output_type":"stream"},{"name":"stderr","text":"Meta Ablation (one-pass + resume):  87%|████████▋ | 253/290 [05:27<00:47,  1.29s/it]","output_type":"stream"},{"name":"stdout","text":"[AVSync] Error computing lipsync for /kaggle/input/localized-audio-visual-deepfake-dataset-lav-df/LAV-DF/test/003436.mp4: InternalError()\n","output_type":"stream"},{"name":"stderr","text":"Meta Ablation (one-pass + resume):  90%|█████████ | 261/290 [05:37<00:35,  1.21s/it]","output_type":"stream"},{"name":"stdout","text":"[AVSync] Error computing lipsync for /kaggle/input/fake-ave-celeb/FakeAVCeleb_v1.2/FakeVideo-FakeAudio/Caucasian (European)/women/id00826/00065_id00495_E46aiMUC4A0_id00806_wavtolip.mp4: InternalError()\n","output_type":"stream"},{"name":"stderr","text":"Meta Ablation (one-pass + resume):  90%|█████████ | 262/290 [05:39<00:36,  1.31s/it]","output_type":"stream"},{"name":"stdout","text":"[AVSync] Error computing lipsync for /kaggle/input/fake-ave-celeb/FakeAVCeleb_v1.2/FakeVideo-FakeAudio/Asian (South)/men/id07768/00143_id03344_vyNnOo6lU0o_id06753_wavtolip.mp4: InternalError()\n","output_type":"stream"},{"name":"stderr","text":"Meta Ablation (one-pass + resume):  92%|█████████▏| 267/290 [05:45<00:28,  1.26s/it]","output_type":"stream"},{"name":"stdout","text":"[AVSync] Error computing lipsync for /kaggle/input/fake-ave-celeb/FakeAVCeleb_v1.2/FakeVideo-FakeAudio/Caucasian (American)/women/id03556/00043_id01004_867Wlj7Gw68_id00458_wavtolip.mp4: InternalError()\n","output_type":"stream"},{"name":"stderr","text":"Meta Ablation (one-pass + resume):  93%|█████████▎| 269/290 [05:48<00:26,  1.26s/it]","output_type":"stream"},{"name":"stdout","text":"[AVSync] Error computing lipsync for /kaggle/input/localized-audio-visual-deepfake-dataset-lav-df/LAV-DF/test/126562.mp4: InternalError()\n","output_type":"stream"},{"name":"stderr","text":"Meta Ablation (one-pass + resume):  93%|█████████▎| 270/290 [05:49<00:28,  1.40s/it]","output_type":"stream"},{"name":"stdout","text":"[heartbeat] 280/300 done | fails=0\n","output_type":"stream"},{"name":"stderr","text":"Meta Ablation (one-pass + resume):  94%|█████████▍| 272/290 [05:52<00:23,  1.33s/it]","output_type":"stream"},{"name":"stdout","text":"[AVSync] Error computing lipsync for /kaggle/input/fake-ave-celeb/FakeAVCeleb_v1.2/FakeVideo-FakeAudio/Caucasian (European)/men/id01098/00044_id00498_wavtolip.mp4: InternalError()\n","output_type":"stream"},{"name":"stderr","text":"Meta Ablation (one-pass + resume):  95%|█████████▍| 275/290 [05:56<00:20,  1.34s/it]","output_type":"stream"},{"name":"stdout","text":"[AVSync] Error computing lipsync for /kaggle/input/localized-audio-visual-deepfake-dataset-lav-df/LAV-DF/test/090345.mp4: InternalError()\n","output_type":"stream"},{"name":"stderr","text":"Meta Ablation (one-pass + resume):  96%|█████████▌| 277/290 [05:59<00:17,  1.35s/it]","output_type":"stream"},{"name":"stdout","text":"[AVSync] Error computing lipsync for /kaggle/input/localized-audio-visual-deepfake-dataset-lav-df/LAV-DF/test/003154.mp4: InternalError()\n","output_type":"stream"},{"name":"stderr","text":"Meta Ablation (one-pass + resume):  97%|█████████▋| 280/290 [06:03<00:13,  1.34s/it]","output_type":"stream"},{"name":"stdout","text":"[AVSync] Error computing lipsync for /kaggle/input/localized-audio-visual-deepfake-dataset-lav-df/LAV-DF/test/114055.mp4: InternalError()\n","output_type":"stream"},{"name":"stderr","text":"Meta Ablation (one-pass + resume):  97%|█████████▋| 281/290 [06:04<00:12,  1.40s/it]","output_type":"stream"},{"name":"stdout","text":"[AVSync] Error computing lipsync for /kaggle/input/localized-audio-visual-deepfake-dataset-lav-df/LAV-DF/test/003781.mp4: InternalError()\n","output_type":"stream"},{"name":"stderr","text":"Meta Ablation (one-pass + resume):  99%|█████████▉| 287/290 [06:12<00:03,  1.30s/it]","output_type":"stream"},{"name":"stdout","text":"[AVSync] Error computing lipsync for /kaggle/input/fake-ave-celeb/FakeAVCeleb_v1.2/FakeVideo-FakeAudio/Caucasian (American)/women/id00848/00028_id00458_K4t1pQZL7ck_id01223_wavtolip.mp4: InternalError()\n","output_type":"stream"},{"name":"stderr","text":"Meta Ablation (one-pass + resume):  99%|█████████▉| 288/290 [06:14<00:02,  1.38s/it]","output_type":"stream"},{"name":"stdout","text":"[AVSync] Error computing lipsync for /kaggle/input/fake-ave-celeb/FakeAVCeleb_v1.2/FakeVideo-FakeAudio/Asian (East)/men/id02332/00055_id02365_wavtolip.mp4: InternalError()\n","output_type":"stream"},{"name":"stderr","text":"Meta Ablation (one-pass + resume): 100%|██████████| 290/290 [06:17<00:00,  1.30s/it]","output_type":"stream"},{"name":"stdout","text":"[heartbeat] 300/300 done | fails=0\n\n================ RESULTS ================\nPlanned: 300\nProcessed: 300\nFailed: 0\nCheckpoint: /kaggle/working/meta_ablation_ckpt.pkl\n========================================\n\nAccuracy (NO metadata) : 0.9967\nAccuracy (WITH metadata): 0.9933\n\nClassification Report (NO metadata):\n              precision    recall  f1-score   support\n\n     Real(0)       1.00      0.99      1.00       150\n     Fake(1)       0.99      1.00      1.00       150\n\n    accuracy                           1.00       300\n   macro avg       1.00      1.00      1.00       300\nweighted avg       1.00      1.00      1.00       300\n\nClassification Report (WITH metadata):\n              precision    recall  f1-score   support\n\n     Real(0)       1.00      0.99      0.99       150\n     Fake(1)       0.99      1.00      0.99       150\n\n    accuracy                           0.99       300\n   macro avg       0.99      0.99      0.99       300\nweighted avg       0.99      0.99      0.99       300\n\nConfusion Matrix (NO metadata):\n [[149   1]\n [  0 150]]\nConfusion Matrix (WITH metadata):\n [[148   2]\n [  0 150]]\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 500x400 with 2 Axes>","image/png":"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\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 500x400 with 2 Axes>","image/png":"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\n"},"metadata":{}},{"name":"stdout","text":"\n=========== McNemar Test ===========\nb (no-meta correct, meta wrong): 1\nc (no-meta wrong, meta correct): 0\nNet gain (c-b): -1\np-value: 1.0\n❌ Not significant (fail to reject H0)\n====================================\n\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}